{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_new = pd.read_csv('../data/clean_data.csv', sep='\\t')\n",
    "df_new.dropna(subset=['events'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = df_new['content'].tolist()\n",
    "events = df_new['events'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished extracting 25000 docutments\n"
     ]
    }
   ],
   "source": [
    "file1 = open(\"../data/documents_labeled.txt\",\"w\")\n",
    "count = 0\n",
    "for i in range(len(documents)):\n",
    "#     if ' '.join(set(events[i].split())) == '股价下跌':\n",
    "    file1.write(documents[i] + \"\\n\")\n",
    "    count += 1\n",
    "    if count == 25000:\n",
    "        break\n",
    "file1.close()\n",
    "\n",
    "print(\"finished extracting {} docutments\".format(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import gensim\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stopwords(stopwords_path):\n",
    "    with open(stopwords_path, 'r', encoding='utf-8') as f:\n",
    "        return [line.strip() for line in f]\n",
    "    \n",
    "def preprocess_data(corpus_path, stopwords):\n",
    "    corpus = []\n",
    "    with open(corpus_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = ''.join(line.split())\n",
    "            corpus.append(' '.join([word for word in jieba.lcut(line.strip()) if word not in stopwords]))\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "2020-06-18 15:55:38,237 : DEBUG : Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/m3/4yh806w92fdgcn0bk16ql7nw0000gn/T/jieba.cache\n",
      "2020-06-18 15:55:38,240 : DEBUG : Loading model from cache /var/folders/m3/4yh806w92fdgcn0bk16ql7nw0000gn/T/jieba.cache\n",
      "Loading model cost 0.955 seconds.\n",
      "2020-06-18 15:55:39,193 : DEBUG : Loading model cost 0.955 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "2020-06-18 15:55:39,195 : DEBUG : Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "stopwords_path = \"../data/stop_words.txt\"\n",
    "documents_path = \"../data/documents_股价上涨.txt\"\n",
    "stopwords = load_stopwords(stopwords_path)\n",
    "documents = preprocess_data(documents_path, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpuses = []\n",
    "with open(documents_path, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        line = ''.join(line.split())\n",
    "        corpuses.append(line)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "BITS = 31\n",
    "class simHash(object):\n",
    "# 初始化，遍历文档（已分词），得到词汇表，并进行32位(能表示2^32种情况，完全足够)\\\n",
    "#hash编码和对应的idf值，将idf值作为其权重进行运算，分别存入两个字典(dict)\n",
    "    def __init__(self, documents):\n",
    "        f = documents\n",
    "        dictHash = dict()\n",
    "        dictWeight = dict()\n",
    "        i = 0#hash编码\n",
    "        lines = 0#记录文本数量,以计算idf值\n",
    "        #遍历文本，进行hash编码和统计df词频(在多少篇文章出现过，而不是总词频，\\\n",
    "        #比如某个词在一个文本中出现三次也只算一次)\n",
    "        for line in f:\n",
    "            lines += 1\n",
    "            temp = set(str(line).strip().split())#避免重复统计词频\n",
    "            for item in temp:\n",
    "                if item not in stopwords:\n",
    "                    if item not in dictWeight:\n",
    "                        dictWeight[item] = 1\n",
    "                        dictHash[item] = i\n",
    "                        i += 1\n",
    "                    else:\n",
    "                        dictWeight[item] += 1\n",
    "        del i\n",
    "        #hash编码转为array形式的二进制，方便计算\n",
    "        for item in dictHash:\n",
    "            L = list(bin(dictHash[item]))[2:]\n",
    "            intL = [int(x) for x in L]\n",
    "            for i in range(len(intL)):\n",
    "                if intL[i] == 0:\n",
    "                    intL[i] = -1\n",
    "            intL = (BITS - len(intL))*[-1]+intL\n",
    "            dictHash[item] = np.array(intL)\n",
    "        #根据词频计算idf值\n",
    "        for item in dictWeight:\n",
    "            dictWeight[item] = math.log(lines/dictWeight[item])\n",
    "\n",
    "        self.dictHash = dictHash\n",
    "        self.dictWeight = dictWeight\n",
    "        \n",
    "    #根据词的hash对句子进行hash编码\n",
    "    def senHash(self, sen):\n",
    "        senHashCode = np.zeros(BITS)\n",
    "        temp = sen.strip().split()\n",
    "        for item in temp:\n",
    "            senHashCode += self.dictHash[item]*self.dictWeight[item]\n",
    "        for i in range(BITS):\n",
    "            if senHashCode[i] > 0:\n",
    "                senHashCode[i] = 1\n",
    "            else:\n",
    "                senHashCode[i] = 0\n",
    "        return senHashCode\n",
    "\n",
    "    #获取两个句子的Hamming distance，dis越小说明相似度越高\n",
    "    def sen2senDis(self, sen1, sen2):\n",
    "        temp1 = self.senHash(sen1)\n",
    "        temp2 = self.senHash(sen2)\n",
    "        Hamming = 0\n",
    "        for i in range(BITS):\n",
    "            if temp1[i] != temp2[i]:\n",
    "                Hamming += 1\n",
    "        return Hamming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "simhash = simHash(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "  1 -1 -1 -1  1 -1 -1]\n",
      "1.029340723324554\n"
     ]
    }
   ],
   "source": [
    "print(simhash.dictHash['上涨'])\n",
    "print(simhash.dictWeight['上涨'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10763"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 571\n"
     ]
    }
   ],
   "source": [
    "minSimHash = 10000\n",
    "minSimHashIndex = -1\n",
    "for i in range(0, len(documents)):\n",
    "    if i == 100:continue\n",
    "    temp = simhash.sen2senDis(documents[100], documents[i])\n",
    "    if temp < minSimHash:\n",
    "        minSimHash = temp\n",
    "        minSimHashIndex = i\n",
    "        \n",
    "print(minSimHash, minSimHashIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "格隆汇 月 日 丨 啤酒 板块 走强 珠江 啤酒 盘中 一度 涨停 现涨 青岛 啤酒 涨近 惠泉 啤酒 燕京啤酒 集体 走高 近期 餐饮行业 复工 进度 加快 有利于 酒类 行业 恢复 历史 经验 二季度 酒类 板块 收益 概率 酒类 板块 迎来 最佳 配置 期川财 证券 指出 中国 啤酒 行业 步入 高端 机遇期 未来 产品 结构 升级 业绩 增长 核心 驱动力 消费 场景 消费 偏好 角度 短期 疫情 影响 预计 啤酒 家庭 自饮 消费 占 提升 长期 利好 注重 产品品质 差异化 更优 头部 品牌\n",
      "事件 具体内容 月 日二 十国集团 农业部长 视频会议 会后 发表 声明 十国集团 农业部长 承诺 紧密 合作 维护 全球 粮食安全 声明 重申 努力 确保 粮食 产品 农业 粮食 生产 必需 投入品 跨境 流动 重要性 努力 确保 农业 粮食 供应链 工人 健康 福利 流动性 公司 紧紧围绕 农业 食品 两大 产业 全球 资源 中国 市场 发展 理念 专注 公司 农资 粮食 贸易 乳业 肉牛 三大 业务 二级 市场走势 该股 今日 强势 上涨 后市 有望 冲高\n"
     ]
    }
   ],
   "source": [
    "print(documents[100])\n",
    "print(documents[571])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simhash.sen2senDis(documents[0], documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findsimilar(index, documents):\n",
    "    minSimHash = 10000\n",
    "    minSimHashIndex = -1\n",
    "    sim0, sim1, sim2 = [], [], []\n",
    "    for i in range(0, len(documents)):\n",
    "        if i == index:continue\n",
    "        temp = simhash.sen2senDis(documents[index], documents[i])\n",
    "        if temp == 0 : sim0.append(i)\n",
    "        if temp == 1 : sim1.append(i)\n",
    "        if temp == 2 : sim2.append(i)\n",
    "            \n",
    "        if temp < minSimHash:\n",
    "            minSimHash = temp\n",
    "            minSimHashIndex = i\n",
    "    print(minSimHash, minSimHashIndex)\n",
    "    return sim0, sim1, sim2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 667\n"
     ]
    }
   ],
   "source": [
    "sim0, sim1, sim2 = findsimilar(999, documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 100, 102, 170, 232, 340, 343, 477, 483, 509, 571, 682, 742, 780, 1127, 1178, 1196, 1244, 1346, 1385, 1388, 1450, 1485, 1512, 1548, 1569, 1667, 1703, 1748, 1814, 1824, 1839, 1844, 1990, 2017, 2024, 2086, 2128, 2169, 2256, 2262, 2308, 2354, 2439, 2442, 2463, 2473, 2493, 2585, 2610, 2749, 2790, 2848, 2960, 3103, 3107, 3122, 3127, 3156, 3177, 3230, 3274, 3292, 3366, 3506, 3585, 3649, 3703, 3746, 3751, 3923, 3949, 4078, 4239, 4261, 4297, 4389, 4401, 4426, 4487, 4490, 4519, 4522, 4539, 4540, 4541, 4561, 4584, 4616, 4666, 4728, 4817, 4829, 4933, 4982, 5111, 5144, 5147, 5170, 5171, 5212, 5275, 5353, 5377, 5441, 5474, 5481, 5483, 5493, 5498, 5594, 5640, 5647, 5658, 5661, 5720, 5736, 5766, 5813, 5907, 5932, 5997, 6051, 6073, 6162, 6178, 6343, 6349, 6385, 6444, 6504, 6514, 6538, 6560, 6568, 6575, 6613, 6641, 6675, 6678, 6690, 6699, 6714, 6726, 6824, 6908, 6913, 6915, 6943, 6959, 6981, 7031, 7045, 7150, 7155, 7175, 7180, 7182, 7196, 7228, 7251, 7255, 7261, 7263, 7269, 7276, 7279, 7306, 7326, 7372, 7376, 7547, 7651, 7663, 7680, 7681, 7703, 7732, 7754, 7839, 7880, 7887, 7918, 8073, 8079, 8210, 8255, 8267, 8365, 8379, 8387, 8411, 8474, 8539, 8596, 8625, 8639, 8640, 8734, 8774, 8779, 8843, 8972, 9027, 9082, 9092, 9104, 9120, 9131, 9141, 9175, 9210, 9235, 9252, 9261, 9326, 9363, 9389, 9444, 9457, 9463, 9509, 9525, 9585, 9654, 9697, 9745, 9756, 9800, 9831, 9898, 9955, 10003, 10009, 10054, 10151, 10152, 10187, 10224, 10257, 10266, 10270, 10293, 10725, 10736]\n"
     ]
    }
   ],
   "source": [
    "print(sim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "格隆汇4月23日丨国美系继续上涨国美通讯600898.SH再度封板本周暂四日三板累涨近40国美零售0493.HK涨逾3本周暂累涨逾34中关村涨近2国美通讯昨晚公布公司筹划重大资产重组拟通过现金出售的方式向北京美昊投资出售浙江德景电子100股权此举将有利于进一步提升上市公司质量此外上周末国美零售发公告称向拼多多溢价66.44发行2亿美元3年期可转债\n",
      "新浪财经讯4月23日消息食品加工制造板块拉升截至发稿海欣食品拉升涨停龙大肉食盐津铺子克明面业金字火腿等跟涨责任编辑田原\n",
      "以下是御银股份在北京时间4月16日1354分盘口异动快照4月16日御银股份盘中涨幅达5截至13点54分报4.66元成交9442.09万元换手率2.72注以上信息仅供参考不对您构成任何投资建议\n",
      "事件具体内容中国电信中国移动中国联通联合举行线上发布会发布5G消息白皮书阐述了5G消息的核心理念明确了相关业务功能及技术需求提出了对5G消息生态建设的若干构想有业内人士称白皮书的发布有助于三大运营商之间的互联互通打通RCS服务壁垒加速RCS产业发展公司有虚拟运营商牌照和三大运营商有合作公司依靠自主研发的应用软件系统目前已发展成为国内通过SaaS模式为中小企业信息化建设提供软件应用及服务最主要的提供商之一是国际知名的为全球企业用户组织机构及个人用户提供互联网应用服务的提供商ASP二级市场走势该股今日强势上涨后市有望继续冲高\n",
      "以下是沃特股份在北京时间4月13日1431分盘口异动快照4月13日14点31分沃特股份盘中打开涨停现报29.19元成交2.56亿元换手率18.48该股之前于14点30分涨停注以上信息仅供参考不对您构成任何投资建议\n",
      "以五粮液为代表的中国白酒有着3000多年的酿造历史堪称世界最古老最具神秘特色的食品制造产业之一五粮液作为曾经的白酒老大在经历了塑化剂事件之后随着近年来新的管理层励精图治之后逐步回归到人们的视野中2019年从市场表现来看遭北上资金重点加仓的股票明显跑赢市场贵州茅台五粮液等更已翻倍遭北上资金抛弃的股票大多跑输市场平均作为港股通的重仓股价值投资的典范之一我们试着以后视镜的角度出发以2010年12月31日的收盘价买入100股五粮液回测下持有至今的收益率截止2020年4月9日五粮液的收盘价124.98元2010年12月31日收盘价34.63元100股成本3463元期间无拆股派息如下总分红760元目前100股市值为12498元不考虑分红的利息率的情况下10年收益760124983463=3.83倍个人认为近四年来五粮液的价值在于其翻倍上涨的股价但是对于股价已经涨了5倍的五粮液来说现在其并不适合长期持有从五粮液近10年的分红收益可以看的出近十年五粮液的分红收益率不到2后视镜系列过往文章后视镜系列美的集团上市当日买入100股现在收益多少后视镜系列2011年买入十手双汇发展免责声明本文来自腾讯新闻客户端自媒体不代表腾讯网的观点和立场\n"
     ]
    }
   ],
   "source": [
    "print(corpuses[999])\n",
    "print(corpuses[667])\n",
    "print(corpuses[2715])\n",
    "print(corpuses[4438])\n",
    "print(corpuses[4951])\n",
    "print(corpuses[5473])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 249\n"
     ]
    }
   ],
   "source": [
    "maxSimHash = 0\n",
    "maxSimHashIndex = -1\n",
    "for i in range(0, len(documents)):\n",
    "    if i == 100:continue\n",
    "    temp = simhash.sen2senDis(documents[100], documents[i])\n",
    "    if temp > maxSimHashIndex:\n",
    "        maxSimHash = temp\n",
    "        maxSimHashIndex = i\n",
    "        \n",
    "print(maxSimHash, maxSimHashIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合 锻 智能 北京 时间 月 日 1021 分盘口 异动 快照 月 日合 锻 智能 盘中 涨幅 达 点 分报 5.71 成交 4701.68 换手率 1.88 注 信息 仅供参考 投资 建议\n",
      "格隆汇 月 日 丨 啤酒 板块 走强 珠江 啤酒 盘中 一度 涨停 现涨 青岛 啤酒 涨近 惠泉 啤酒 燕京啤酒 集体 走高 近期 餐饮行业 复工 进度 加快 有利于 酒类 行业 恢复 历史 经验 二季度 酒类 板块 收益 概率 酒类 板块 迎来 最佳 配置 期川财 证券 指出 中国 啤酒 行业 步入 高端 机遇期 未来 产品 结构 升级 业绩 增长 核心 驱动力 消费 场景 消费 偏好 角度 短期 疫情 影响 预计 啤酒 家庭 自饮 消费 占 提升 长期 利好 注重 产品品质 差异化 更优 头部 品牌\n"
     ]
    }
   ],
   "source": [
    "print(documents[249])\n",
    "print(documents[100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pDL] *",
   "language": "python",
   "name": "conda-env-pDL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
