{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stopwords(stopwords_path):\n",
    "    with open(stopwords_path, 'r', encoding='utf-8') as f:\n",
    "        return [line.strip() for line in f]\n",
    "    \n",
    "def preprocess_data(corpus_path, stopwords):\n",
    "    corpus = []\n",
    "    with open(corpus_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            corpus.append(' '.join([word for word in jieba.lcut(line.strip()) if word not in stopwords]))\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "2020-06-15 09:37:30,471 : DEBUG : Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/m3/4yh806w92fdgcn0bk16ql7nw0000gn/T/jieba.cache\n",
      "2020-06-15 09:37:30,474 : DEBUG : Loading model from cache /var/folders/m3/4yh806w92fdgcn0bk16ql7nw0000gn/T/jieba.cache\n",
      "Loading model cost 0.638 seconds.\n",
      "2020-06-15 09:37:31,111 : DEBUG : Loading model cost 0.638 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "2020-06-15 09:37:31,112 : DEBUG : Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "stopwords_path = \"../data/stop_words.txt\"\n",
    "documents_path = \"../data/documents_first_\" + str(n) + \".txt\"\n",
    "stopwords = load_stopwords(stopwords_path)\n",
    "documents = preprocess_data(documents_path, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'董明珠 惊人 之语 炮轰 美的 怒斥 国产车 炮火 引向 大众 这下 本来 习惯于 看热闹 吃 瓜 群众 答应 踩 同行 骂 竞争对手 意见 敢动 老子 一亩 三分 不行 014 月 日 晚间 格力电器 董事长 兼 总裁 董明珠 接受 采访 时 赞同 黄奇帆 取消 住房 公积金 说 格力电器 3700 套 房子 员工 入住 未来 格力 员工 发一 套房 公积金 听听 话 饱汉不知饿汉饥 专程来 炫富 经济 下行 大众 钱包 吃紧 格力 本事 每名 员工 分 房子 本事 格力 分房 取消 全国 公积金 站长 想 问 一句 董 小姐 蠢 坏 确实 格力 优秀 年 营业 收入 1981.53 拥有 万名 员工 格力 万名 员工 发一 套房 站长 说 信 格力 真 员工 分房 中国 企业 众多 能发 房子 企业 凤毛麟角 特别 受 疫情 影响 众多 行业 暴击 企业 濒临 倒闭 活着 不错 每人 发 套房 格力 员工 公积金 取消 公积金 格力 确实 省下 一大笔钱 我国 亿人 贫富差距 取消 公积金 势必会 影响 人群 利益 也许 董明珠 换种 表述 特定 福利 企业 取消 缴纳 公积金 企业 节约 成本 用于 研发 创新 公积金 整体 实施 影响 我国 当初 建立 住房 公积金 制度 新加坡 学习 希望 强制性 缴纳 办法 集合 政府 企业 职工 三方 力量 解决 民众 购房 中国 最先 实行 公积金 政策 上海 全国 房地产 市场 发展 实行 公房 分配制度 家庭 人均 住房面积 七八 平方米 住 拥挤 居住 环境 急需 改善 公积金 强制 缴存 看似 个人收入 减少 长期 并非如此 民企 公积金 缴纳 比例 5% 12% 薪资 基数 缴纳 比例 6% 公司 6% 12% 公积金 存缴 数额 50006% 别看 元不多 长此以往 可不是 小数 缴纳 时间 公积金 买房 提取 大众 福利 特别 事业单位 公务员 群体 公积金 缴纳 金额 高 一般来说 公务员 月 公积金 扣除 比例 工资 12% 公积金 政策 国家 补贴 数额 公务员 一个月 公积金 工资 24% 民企 两倍 账面 工资 特别 高 公务员 群体 公积金 住 建部 人民银行 总行 统计 显示 年 全国 住房 公积金 缴存 总额 14549.46 上年 增长 12.29% 缴存 人数 机关 事业单位 工作人员 国企 职工 缴存 住房 公积金 比例 占 年 缴存 总额 60.16% 占 高 年 城镇 私 民 营 企业 城镇 企业 缴纳 住房 公积金 占 总额 19.5% 公积金 公务员 群体 至关重要 普通人 公积金 房价 高昂 公积金 居民 低息 房贷 唯一 渠道 全国 住房 公积金 年 年度报告 显示 年末 累计 发放 住房贷款 3334.82 万笔 85821.32 人员 置业 首 套房 贷款 年 公积金 利率 3.25% 二套 3.75% 远 商贷 首 套房 贷款 平均 利率 5.5% 假设 贷款 年 期限 公积金 贷款 商业贷款 节省 利息 约 笔 不小 资金 取消 公积金 将会 损害 大部分 利益 举个 例子 刘 缴纳 公积金 比例 12% 月 缴存 652 年 3.25% 利率 贷款 购买 一套 住房 每月 还款 可用 公积金 冲抵 979 每月 还款 多元 公积金 减轻 购房 压力 用处 很大 缴纳 住房 公积金 好处 少 缴纳 个人所得税 计算 个税 减去 住房 公积金 数额 不论是 单位 缴纳 缴纳 实惠 很大 公积金 提取 不断扩大 公积金 效率 提升 买房 装修 可用 租房 大病 提取 当今 疫情 部门 发出通知 新冠 肺炎 患者 提取 住房 公积金 用于 医疗 支出 买房 账户 里 公积金 退休 取出 生活 改善 说 公积金 用处 只能 租房 买房 公积金 表面 事 关乎 国家 大部 利益 开发商 公积金 制度 降低 买房 门槛 买房 人会 有利于 房企 发展 地方 政府 开发商 有钱 买 缴纳 土地 出让金 有利于 地方 财政 说 专家 说 取消 公积金 可取 稍微 动动脑 子 甄别 利弊 类 声音 就行 跑 偏 免责 声明 本文 腾讯 新闻 客户端 媒体 代表 腾讯网 观点 立场'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [[word for word in document.split()] for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "texts = [[token for token in text if frequency[token] > 2] for text in texts]\n",
    "# pprint(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-15 09:37:45,315 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-06-15 09:37:45,481 : INFO : built Dictionary(11105 unique tokens: ['15%', '18%', '46%', '一周', '世界']...) from 1005 documents (total 200743 corpus positions)\n",
      "2020-06-15 09:37:45,483 : INFO : saving Dictionary object under ../data/first_1000_doc.dict, separately None\n",
      "2020-06-15 09:37:45,490 : INFO : saved ../data/first_1000_doc.dict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(11105 unique tokens: ['15%', '18%', '46%', '一周', '世界']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.save('../data/first_' + str(n) + '_doc.dict')\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-15 09:37:45,657 : INFO : storing corpus in Matrix Market format to ../data/first_1000_doc.mm\n",
      "2020-06-15 09:37:45,657 : INFO : saving sparse matrix to ../data/first_1000_doc.mm\n",
      "2020-06-15 09:37:45,658 : INFO : PROGRESS: saving document #0\n",
      "2020-06-15 09:37:45,776 : INFO : PROGRESS: saving document #1000\n",
      "2020-06-15 09:37:45,777 : INFO : saved 1005x11105 matrix, density=0.982% (109589/11160525)\n",
      "2020-06-15 09:37:45,778 : INFO : saving MmCorpus index to ../data/first_1000_doc.mm.index\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "corpora.MmCorpus.serialize('../data/first_' + str(n) + '_doc.mm', corpus)\n",
    "# pprint(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-15 09:37:45,783 : INFO : collecting document frequencies\n",
      "2020-06-15 09:37:45,784 : INFO : PROGRESS: processing document #0\n",
      "2020-06-15 09:37:45,802 : INFO : calculating IDF weights for 1005 documents and 11105 features (109589 matrix non-zeros)\n"
     ]
    }
   ],
   "source": [
    "from gensim import models, similarities\n",
    "tf_idf = models.TfidfModel(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1),\n",
      "  (1, 1),\n",
      "  (2, 1),\n",
      "  (3, 1),\n",
      "  (4, 1),\n",
      "  (5, 1),\n",
      "  (6, 1),\n",
      "  (7, 1),\n",
      "  (8, 1),\n",
      "  (9, 2),\n",
      "  (10, 1),\n",
      "  (11, 3),\n",
      "  (12, 1),\n",
      "  (13, 4),\n",
      "  (14, 1),\n",
      "  (15, 1),\n",
      "  (16, 1),\n",
      "  (17, 1),\n",
      "  (18, 2),\n",
      "  (19, 4),\n",
      "  (20, 1),\n",
      "  (21, 1),\n",
      "  (22, 2),\n",
      "  (23, 1),\n",
      "  (24, 1),\n",
      "  (25, 1),\n",
      "  (26, 2),\n",
      "  (27, 1),\n",
      "  (28, 1),\n",
      "  (29, 3),\n",
      "  (30, 1),\n",
      "  (31, 1),\n",
      "  (32, 1),\n",
      "  (33, 1),\n",
      "  (34, 1),\n",
      "  (35, 1),\n",
      "  (36, 1),\n",
      "  (37, 1),\n",
      "  (38, 2),\n",
      "  (39, 1),\n",
      "  (40, 1),\n",
      "  (41, 5),\n",
      "  (42, 1),\n",
      "  (43, 1),\n",
      "  (44, 1),\n",
      "  (45, 2),\n",
      "  (46, 2),\n",
      "  (47, 2),\n",
      "  (48, 1),\n",
      "  (49, 1),\n",
      "  (50, 2),\n",
      "  (51, 3),\n",
      "  (52, 2),\n",
      "  (53, 1),\n",
      "  (54, 2),\n",
      "  (55, 1),\n",
      "  (56, 5),\n",
      "  (57, 1),\n",
      "  (58, 5),\n",
      "  (59, 1),\n",
      "  (60, 1),\n",
      "  (61, 1),\n",
      "  (62, 1),\n",
      "  (63, 3),\n",
      "  (64, 1),\n",
      "  (65, 2),\n",
      "  (66, 1),\n",
      "  (67, 2),\n",
      "  (68, 4),\n",
      "  (69, 1),\n",
      "  (70, 1),\n",
      "  (71, 1),\n",
      "  (72, 2),\n",
      "  (73, 2),\n",
      "  (74, 1),\n",
      "  (75, 1)],\n",
      " [(43, 1),\n",
      "  (45, 1),\n",
      "  (76, 2),\n",
      "  (77, 1),\n",
      "  (78, 1),\n",
      "  (79, 3),\n",
      "  (80, 1),\n",
      "  (81, 1),\n",
      "  (82, 1),\n",
      "  (83, 2),\n",
      "  (84, 1),\n",
      "  (85, 4),\n",
      "  (86, 1),\n",
      "  (87, 1),\n",
      "  (88, 1),\n",
      "  (89, 1),\n",
      "  (90, 1),\n",
      "  (91, 1),\n",
      "  (92, 1),\n",
      "  (93, 1),\n",
      "  (94, 1),\n",
      "  (95, 1),\n",
      "  (96, 3),\n",
      "  (97, 2),\n",
      "  (98, 1),\n",
      "  (99, 3),\n",
      "  (100, 2),\n",
      "  (101, 1),\n",
      "  (102, 1),\n",
      "  (103, 1),\n",
      "  (104, 1),\n",
      "  (105, 1),\n",
      "  (106, 1),\n",
      "  (107, 6),\n",
      "  (108, 1),\n",
      "  (109, 1),\n",
      "  (110, 1),\n",
      "  (111, 3),\n",
      "  (112, 1),\n",
      "  (113, 1),\n",
      "  (114, 1),\n",
      "  (115, 1),\n",
      "  (116, 3),\n",
      "  (117, 2),\n",
      "  (118, 2),\n",
      "  (119, 1),\n",
      "  (120, 1),\n",
      "  (121, 1),\n",
      "  (122, 2),\n",
      "  (123, 2),\n",
      "  (124, 2),\n",
      "  (125, 2),\n",
      "  (126, 2),\n",
      "  (127, 2),\n",
      "  (128, 3),\n",
      "  (129, 3),\n",
      "  (130, 1),\n",
      "  (131, 1),\n",
      "  (132, 3),\n",
      "  (133, 1),\n",
      "  (134, 1),\n",
      "  (135, 1),\n",
      "  (136, 7),\n",
      "  (137, 1),\n",
      "  (138, 2),\n",
      "  (139, 1),\n",
      "  (140, 1),\n",
      "  (141, 1),\n",
      "  (142, 1),\n",
      "  (143, 1),\n",
      "  (144, 1),\n",
      "  (145, 1),\n",
      "  (146, 1),\n",
      "  (147, 1),\n",
      "  (148, 10),\n",
      "  (149, 2),\n",
      "  (150, 1),\n",
      "  (151, 2),\n",
      "  (152, 1),\n",
      "  (153, 2),\n",
      "  (154, 1),\n",
      "  (155, 1),\n",
      "  (156, 1),\n",
      "  (157, 1),\n",
      "  (158, 9),\n",
      "  (159, 3),\n",
      "  (160, 1),\n",
      "  (161, 2),\n",
      "  (162, 7),\n",
      "  (163, 2),\n",
      "  (164, 4),\n",
      "  (165, 1),\n",
      "  (166, 1),\n",
      "  (167, 1),\n",
      "  (168, 1),\n",
      "  (169, 2),\n",
      "  (170, 1),\n",
      "  (171, 1),\n",
      "  (172, 1),\n",
      "  (173, 20),\n",
      "  (174, 1),\n",
      "  (175, 1),\n",
      "  (176, 1),\n",
      "  (177, 4),\n",
      "  (178, 1),\n",
      "  (179, 3),\n",
      "  (180, 1),\n",
      "  (181, 1),\n",
      "  (182, 1),\n",
      "  (183, 1),\n",
      "  (184, 2),\n",
      "  (185, 2),\n",
      "  (186, 2),\n",
      "  (187, 1),\n",
      "  (188, 3),\n",
      "  (189, 1),\n",
      "  (190, 1),\n",
      "  (191, 1),\n",
      "  (192, 1),\n",
      "  (193, 1),\n",
      "  (194, 1),\n",
      "  (195, 1),\n",
      "  (196, 1),\n",
      "  (197, 1),\n",
      "  (198, 1),\n",
      "  (199, 1),\n",
      "  (200, 1),\n",
      "  (201, 1),\n",
      "  (202, 1),\n",
      "  (203, 1),\n",
      "  (204, 1),\n",
      "  (205, 2),\n",
      "  (206, 1),\n",
      "  (207, 7),\n",
      "  (208, 1),\n",
      "  (209, 1),\n",
      "  (210, 2),\n",
      "  (211, 1),\n",
      "  (212, 3),\n",
      "  (213, 4),\n",
      "  (214, 1),\n",
      "  (215, 7),\n",
      "  (216, 1),\n",
      "  (217, 1),\n",
      "  (218, 1),\n",
      "  (219, 1),\n",
      "  (220, 1),\n",
      "  (221, 1),\n",
      "  (222, 1),\n",
      "  (223, 1),\n",
      "  (224, 2),\n",
      "  (225, 1),\n",
      "  (226, 3),\n",
      "  (227, 1),\n",
      "  (228, 1),\n",
      "  (229, 1),\n",
      "  (230, 1),\n",
      "  (231, 3),\n",
      "  (232, 2),\n",
      "  (233, 1),\n",
      "  (234, 2),\n",
      "  (235, 3)]]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(corpus[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-15 09:37:45,844 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n",
      "2020-06-15 09:37:46,342 : INFO : creating matrix with 1005 documents and 11105 features\n"
     ]
    }
   ],
   "source": [
    "index = similarities.MatrixSimilarity(tf_idf[corpus])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 0.8459525\n",
      "483 0.11595668\n",
      "653 0.11566185\n",
      "443 0.08606418\n",
      "622 0.0748373\n",
      "298 0.07418704\n",
      "339 0.071005516\n",
      "327 0.06818734\n",
      "371 0.06796195\n",
      "315 0.06487929\n",
      "348 0.06225711\n",
      "956 0.059957404\n",
      "165 0.05980962\n",
      "996 0.054670077\n",
      "778 0.053686388\n",
      "82 0.052728444\n",
      "597 0.051916204\n",
      "751 0.051364847\n",
      "707 0.043157633\n",
      "846 0.041981574\n",
      "580 0.03954599\n",
      "788 0.038054198\n",
      "296 0.03713871\n",
      "36 0.036963742\n",
      "879 0.0368164\n",
      "21 0.036739632\n",
      "440 0.035467554\n",
      "953 0.033900443\n",
      "35 0.033481337\n",
      "913 0.033455756\n",
      "271 0.03276166\n",
      "221 0.032736387\n",
      "334 0.03246125\n",
      "507 0.03174052\n",
      "499 0.031045455\n",
      "797 0.031032456\n",
      "311 0.030903686\n",
      "312 0.030280098\n",
      "680 0.029878343\n",
      "461 0.029806994\n",
      "116 0.029659348\n",
      "148 0.029653452\n",
      "243 0.029493464\n",
      "113 0.028947107\n",
      "816 0.02846191\n",
      "46 0.028146721\n",
      "669 0.027783422\n",
      "292 0.027584933\n",
      "9 0.027326383\n",
      "520 0.027126888\n",
      "3 0.026542025\n",
      "233 0.02637478\n",
      "65 0.025726298\n",
      "943 0.025676448\n",
      "399 0.025495697\n",
      "807 0.025269594\n",
      "414 0.025067756\n",
      "344 0.024766719\n",
      "532 0.024764955\n",
      "269 0.024758764\n",
      "44 0.02407913\n",
      "88 0.02406754\n",
      "976 0.024049094\n",
      "761 0.023970228\n",
      "505 0.023898652\n",
      "231 0.023809776\n",
      "808 0.023807742\n",
      "931 0.02372852\n",
      "766 0.023541689\n",
      "306 0.02347046\n",
      "682 0.023441236\n",
      "952 0.0231792\n",
      "702 0.023097375\n",
      "955 0.023058642\n",
      "925 0.022994846\n",
      "742 0.022980813\n",
      "932 0.022813337\n",
      "905 0.022527184\n",
      "538 0.021580994\n",
      "1003 0.02149614\n",
      "1004 0.021429028\n",
      "848 0.020818498\n",
      "548 0.020796688\n",
      "450 0.020754026\n",
      "264 0.020428648\n",
      "33 0.020267164\n",
      "713 0.020044\n",
      "540 0.019856654\n",
      "71 0.01980493\n",
      "997 0.019798197\n",
      "710 0.019740097\n",
      "176 0.01957261\n",
      "512 0.019329555\n",
      "442 0.019019343\n",
      "709 0.018791975\n",
      "784 0.018584918\n",
      "777 0.018281804\n",
      "413 0.018274926\n",
      "894 0.018239176\n",
      "740 0.01820739\n",
      "488 0.018160911\n",
      "985 0.018061591\n",
      "914 0.01801332\n",
      "861 0.017973652\n",
      "688 0.017973125\n",
      "390 0.017900769\n",
      "673 0.017754335\n",
      "690 0.017531276\n",
      "83 0.017467303\n",
      "370 0.017463777\n",
      "487 0.017444469\n",
      "368 0.0174179\n",
      "631 0.017387705\n",
      "573 0.017350443\n",
      "741 0.017317902\n",
      "659 0.01728392\n",
      "26 0.017266266\n",
      "434 0.016987707\n",
      "860 0.016949467\n",
      "486 0.01692566\n",
      "358 0.016773654\n",
      "836 0.016687304\n",
      "521 0.016615361\n",
      "747 0.016524037\n",
      "833 0.016478905\n",
      "717 0.016446438\n",
      "526 0.016418846\n",
      "817 0.016364627\n",
      "93 0.016340867\n",
      "880 0.016265165\n",
      "617 0.016165812\n",
      "209 0.01616314\n",
      "338 0.016133413\n",
      "1001 0.016018962\n",
      "511 0.015998857\n",
      "530 0.015861586\n",
      "266 0.015802983\n",
      "780 0.015781725\n",
      "980 0.015748827\n",
      "940 0.015576841\n",
      "867 0.015564129\n",
      "830 0.01554567\n",
      "856 0.015503338\n",
      "366 0.0152174225\n",
      "890 0.015198754\n",
      "661 0.015194453\n",
      "156 0.015182415\n",
      "899 0.015145569\n",
      "372 0.015125547\n",
      "854 0.015098384\n",
      "599 0.015080191\n",
      "48 0.015022256\n",
      "719 0.01497641\n",
      "853 0.014952242\n",
      "589 0.014952017\n",
      "403 0.014813819\n",
      "918 0.014741383\n",
      "942 0.014721248\n",
      "965 0.014647956\n",
      "377 0.014570211\n",
      "972 0.014402019\n",
      "280 0.014375436\n",
      "504 0.014302092\n",
      "609 0.014251909\n",
      "989 0.014119087\n",
      "839 0.01409388\n",
      "95 0.014034981\n",
      "208 0.014016345\n",
      "884 0.013922916\n",
      "799 0.013898806\n",
      "546 0.013889423\n",
      "887 0.013754347\n",
      "145 0.013719084\n",
      "61 0.01371739\n",
      "62 0.01371739\n",
      "970 0.013692651\n",
      "30 0.013662741\n",
      "849 0.01365783\n",
      "397 0.013638547\n",
      "536 0.013493676\n",
      "706 0.01346356\n",
      "764 0.013435889\n",
      "119 0.013419284\n",
      "73 0.01340176\n",
      "1002 0.013380004\n",
      "693 0.013368126\n",
      "102 0.013358718\n",
      "343 0.013357003\n",
      "666 0.013332015\n",
      "757 0.013305471\n",
      "961 0.01329832\n",
      "528 0.013244494\n",
      "550 0.013241175\n",
      "835 0.013202149\n",
      "531 0.013201799\n",
      "259 0.013183735\n",
      "559 0.0131438\n",
      "606 0.01313887\n",
      "172 0.013084939\n",
      "360 0.013080364\n",
      "657 0.013067212\n",
      "864 0.012920048\n",
      "993 0.012799831\n",
      "963 0.012798132\n",
      "821 0.012771011\n",
      "436 0.012744692\n",
      "439 0.01267063\n",
      "692 0.012666022\n",
      "634 0.012665004\n",
      "190 0.012642583\n",
      "529 0.01255367\n",
      "321 0.012551552\n",
      "954 0.012530599\n",
      "863 0.012529839\n",
      "391 0.012492756\n",
      "326 0.012483796\n",
      "916 0.012431432\n",
      "341 0.0123903565\n",
      "838 0.012359274\n",
      "373 0.012334401\n",
      "419 0.012268011\n",
      "227 0.012266483\n",
      "801 0.012261319\n",
      "847 0.012243242\n",
      "746 0.012222341\n",
      "687 0.012194522\n",
      "771 0.012176327\n",
      "900 0.012101294\n",
      "299 0.012027308\n",
      "832 0.011940178\n",
      "293 0.011933926\n",
      "463 0.011859075\n",
      "581 0.011824661\n",
      "969 0.011779866\n",
      "722 0.011768014\n",
      "398 0.011711538\n",
      "345 0.011696376\n",
      "154 0.011679633\n",
      "132 0.01166601\n",
      "361 0.011664896\n",
      "187 0.011576353\n",
      "715 0.011536887\n",
      "217 0.011529416\n",
      "704 0.011498392\n",
      "758 0.0114973225\n",
      "678 0.011470043\n",
      "862 0.011458181\n",
      "350 0.011428165\n",
      "285 0.0114188\n",
      "703 0.01141705\n",
      "910 0.011403209\n",
      "919 0.011394861\n",
      "696 0.011349998\n",
      "705 0.011349713\n",
      "588 0.011301595\n",
      "251 0.011293361\n",
      "549 0.011288628\n",
      "727 0.011280096\n",
      "873 0.011267615\n",
      "254 0.011247331\n",
      "857 0.011226416\n",
      "844 0.0112186745\n",
      "365 0.011187472\n",
      "728 0.011147689\n",
      "768 0.011083928\n",
      "576 0.011077002\n",
      "265 0.010994272\n",
      "643 0.010971654\n",
      "340 0.010946067\n",
      "566 0.010918375\n",
      "614 0.01090236\n",
      "630 0.010871982\n",
      "240 0.010811069\n",
      "554 0.010798652\n",
      "481 0.010751223\n",
      "960 0.010722283\n",
      "689 0.010721899\n",
      "349 0.010721507\n",
      "819 0.010663389\n",
      "514 0.010653119\n",
      "163 0.0106416205\n",
      "754 0.010619136\n",
      "628 0.010610791\n",
      "933 0.010574289\n",
      "396 0.010516328\n",
      "347 0.010514189\n",
      "781 0.010506168\n",
      "668 0.010476142\n",
      "63 0.010470888\n",
      "991 0.010467746\n",
      "823 0.01041852\n",
      "881 0.010409361\n",
      "885 0.010408218\n",
      "11 0.010333599\n",
      "944 0.010308301\n",
      "489 0.010273928\n",
      "855 0.010253893\n",
      "567 0.010196964\n",
      "624 0.010195965\n",
      "500 0.010189418\n",
      "19 0.010169617\n",
      "42 0.010168005\n",
      "524 0.010167408\n",
      "926 0.010139652\n",
      "519 0.0101251025\n",
      "804 0.010078773\n",
      "587 0.010073828\n",
      "577 0.0100366\n",
      "523 0.010021497\n",
      "915 0.009944167\n",
      "462 0.009879185\n",
      "866 0.009859978\n",
      "936 0.009858449\n",
      "552 0.009834217\n",
      "585 0.009831471\n",
      "101 0.009761919\n",
      "412 0.00972664\n",
      "80 0.009726321\n",
      "572 0.009723239\n",
      "181 0.009712976\n",
      "242 0.009706004\n",
      "551 0.009704122\n",
      "229 0.009670564\n",
      "0 0.009649085\n",
      "616 0.009646751\n",
      "603 0.009622529\n",
      "598 0.009585792\n",
      "255 0.009581497\n",
      "409 0.009547256\n",
      "401 0.009539882\n",
      "146 0.009522265\n",
      "60 0.009483869\n",
      "230 0.0094232755\n",
      "684 0.009417028\n",
      "583 0.009413887\n",
      "133 0.009403328\n",
      "582 0.009349246\n",
      "640 0.009343126\n",
      "518 0.009330954\n",
      "968 0.009308417\n",
      "814 0.009303827\n",
      "241 0.009295461\n",
      "449 0.009285266\n",
      "515 0.0092697805\n",
      "889 0.009266546\n",
      "875 0.009245661\n",
      "695 0.009232702\n",
      "615 0.009203902\n",
      "335 0.009158696\n",
      "408 0.009112502\n",
      "605 0.009098757\n",
      "502 0.009093358\n",
      "917 0.009083634\n",
      "638 0.009060083\n",
      "525 0.0090582\n",
      "294 0.008989903\n",
      "595 0.008972568\n",
      "430 0.008971303\n",
      "564 0.008959252\n",
      "144 0.008953859\n",
      "425 0.008952953\n",
      "565 0.008948847\n",
      "731 0.008938251\n",
      "270 0.008902209\n",
      "649 0.0088655185\n",
      "738 0.008848865\n",
      "928 0.008837783\n",
      "825 0.008800756\n",
      "627 0.008714484\n",
      "328 0.008645779\n",
      "422 0.008629123\n",
      "16 0.008619916\n",
      "683 0.008605301\n",
      "783 0.008602429\n",
      "736 0.008547645\n",
      "386 0.008541383\n",
      "981 0.008510889\n",
      "604 0.008508976\n",
      "496 0.008472647\n",
      "173 0.008424825\n",
      "827 0.008412743\n",
      "613 0.008412032\n",
      "962 0.00841076\n",
      "594 0.008402931\n",
      "639 0.008402475\n",
      "951 0.008396983\n",
      "602 0.008371148\n",
      "47 0.008368339\n",
      "647 0.008324591\n",
      "513 0.008282755\n",
      "104 0.008279538\n",
      "301 0.008264467\n",
      "124 0.00825081\n",
      "686 0.008238599\n",
      "575 0.008237029\n",
      "824 0.008202985\n",
      "635 0.0081972685\n",
      "645 0.008157938\n",
      "792 0.0081565585\n",
      "858 0.0081421705\n",
      "636 0.008134548\n",
      "281 0.0080985\n",
      "785 0.008096265\n",
      "681 0.008076099\n",
      "282 0.008052425\n",
      "553 0.008048839\n",
      "498 0.008042469\n",
      "618 0.007994236\n",
      "612 0.007989551\n",
      "533 0.007960616\n",
      "957 0.007956643\n",
      "570 0.007956249\n",
      "129 0.007951501\n",
      "896 0.007927109\n",
      "662 0.0078957705\n",
      "485 0.007863728\n",
      "770 0.007806622\n",
      "4 0.007766793\n",
      "310 0.0077384263\n",
      "986 0.0077301394\n",
      "924 0.007713144\n",
      "322 0.0076818336\n",
      "121 0.007611906\n",
      "205 0.0075717685\n",
      "815 0.0075001246\n",
      "964 0.007449654\n",
      "52 0.0074471817\n",
      "891 0.007422067\n",
      "417 0.007416761\n",
      "623 0.0073561645\n",
      "407 0.0072876518\n",
      "460 0.0072302287\n",
      "469 0.007160329\n",
      "822 0.007137125\n",
      "813 0.0071221227\n",
      "563 0.007116181\n",
      "663 0.0071028583\n",
      "590 0.0070685195\n",
      "626 0.007067938\n",
      "753 0.0070458916\n",
      "592 0.0070158364\n",
      "911 0.0070115356\n",
      "557 0.0070115235\n",
      "922 0.006968905\n",
      "497 0.0069375522\n",
      "759 0.006924753\n",
      "608 0.0068926797\n",
      "958 0.0068485364\n",
      "541 0.006831037\n",
      "574 0.0068216366\n",
      "675 0.0068162433\n",
      "679 0.006792592\n",
      "454 0.006754024\n",
      "904 0.0067271683\n",
      "457 0.00670146\n",
      "677 0.0066794567\n",
      "224 0.006666186\n",
      "509 0.0066404324\n",
      "406 0.0065725734\n",
      "55 0.0065622968\n",
      "122 0.0065607694\n",
      "882 0.0064407927\n",
      "100 0.0064406404\n",
      "128 0.006434063\n",
      "79 0.006420886\n",
      "584 0.0063905986\n",
      "674 0.0063899355\n",
      "2 0.0063714096\n",
      "990 0.0063435156\n",
      "109 0.0063255876\n",
      "152 0.0062954756\n",
      "721 0.0062810844\n",
      "174 0.006269386\n",
      "755 0.00623268\n",
      "611 0.0061950553\n",
      "455 0.0061650397\n",
      "465 0.0061564688\n",
      "672 0.0060952576\n",
      "169 0.0060888515\n",
      "656 0.006014951\n",
      "313 0.0059259157\n",
      "748 0.005884161\n",
      "998 0.005856491\n",
      "596 0.0058496464\n",
      "859 0.0058314074\n",
      "948 0.005821185\n",
      "999 0.0058161486\n",
      "355 0.005814138\n",
      "10 0.0058077034\n",
      "141 0.005778323\n",
      "427 0.005773965\n",
      "58 0.005734167\n",
      "516 0.005719\n",
      "648 0.0056819734\n",
      "971 0.0055952827\n",
      "228 0.005570539\n",
      "161 0.0055598263\n",
      "929 0.0055436697\n",
      "607 0.005531485\n",
      "620 0.005497104\n",
      "236 0.0054686433\n",
      "503 0.0054509356\n",
      "268 0.0054332027\n",
      "12 0.0054197726\n",
      "730 0.005398583\n",
      "158 0.005375438\n",
      "776 0.005339105\n",
      "841 0.005331205\n",
      "851 0.005314352\n",
      "167 0.0053026974\n",
      "641 0.0052983896\n",
      "389 0.0052921833\n",
      "319 0.0052573713\n",
      "153 0.005241195\n",
      "431 0.0052403286\n",
      "130 0.005201329\n",
      "479 0.0051922337\n",
      "410 0.005190413\n",
      "752 0.0051845233\n",
      "76 0.0051617436\n",
      "385 0.005049765\n",
      "545 0.005042947\n",
      "27 0.005038873\n",
      "131 0.0050342297\n",
      "210 0.005006934\n",
      "650 0.0049896333\n",
      "966 0.0049822815\n",
      "506 0.0049413256\n",
      "820 0.0049302294\n",
      "23 0.0049231583\n",
      "459 0.004916173\n",
      "423 0.004910496\n",
      "786 0.004878233\n",
      "664 0.004878193\n",
      "290 0.004845651\n",
      "90 0.0048331213\n",
      "779 0.0048110485\n",
      "250 0.0047674677\n",
      "151 0.0047592074\n",
      "632 0.004734121\n",
      "850 0.004712605\n",
      "421 0.0047042174\n",
      "364 0.0046972474\n",
      "433 0.0046389205\n",
      "139 0.004565962\n",
      "694 0.004561889\n",
      "876 0.0045396937\n",
      "495 0.004523829\n",
      "763 0.004503211\n",
      "874 0.004480455\n",
      "544 0.004459998\n",
      "354 0.0044591273\n",
      "7 0.0044574495\n",
      "186 0.0044574416\n",
      "252 0.004445703\n",
      "245 0.00441138\n",
      "484 0.0044072354\n",
      "105 0.0043817065\n",
      "895 0.0043610577\n",
      "256 0.0043150517\n",
      "262 0.0042880983\n",
      "137 0.0042849323\n",
      "743 0.00428099\n",
      "472 0.004255399\n",
      "429 0.0042394116\n",
      "878 0.0042163352\n",
      "789 0.0042107645\n",
      "54 0.004189565\n",
      "393 0.0041449945\n",
      "272 0.0041309395\n",
      "160 0.0041262144\n",
      "517 0.00411701\n",
      "476 0.004090421\n",
      "283 0.0040825447\n",
      "267 0.004056112\n",
      "278 0.004004473\n",
      "192 0.003984633\n",
      "464 0.003953032\n",
      "446 0.0039327275\n",
      "983 0.0039012926\n",
      "115 0.0038683768\n",
      "725 0.0038666313\n",
      "43 0.003865763\n",
      "556 0.003865382\n",
      "193 0.0038591265\n",
      "676 0.0038124218\n",
      "1 0.0038100707\n",
      "363 0.0038099303\n",
      "277 0.0037851725\n",
      "558 0.0037780907\n",
      "253 0.0037580235\n",
      "652 0.003732406\n",
      "103 0.0037062734\n",
      "126 0.0036957767\n",
      "729 0.0036712836\n",
      "805 0.003669937\n",
      "260 0.0036533587\n",
      "987 0.0036167665\n",
      "775 0.0036118678\n",
      "286 0.0035672493\n",
      "219 0.0035509996\n",
      "798 0.0035448708\n",
      "543 0.0035255312\n",
      "155 0.0035233214\n",
      "353 0.0034820277\n",
      "22 0.0034768975\n",
      "5 0.003472436\n",
      "735 0.0034480053\n",
      "184 0.003444627\n",
      "888 0.0034315214\n",
      "287 0.003430458\n",
      "56 0.0034231408\n",
      "420 0.0033848903\n",
      "127 0.0033750653\n",
      "387 0.0033730832\n",
      "51 0.0033568237\n",
      "84 0.003345826\n",
      "834 0.0033379716\n",
      "912 0.003319397\n",
      "388 0.0033181347\n",
      "31 0.0033096331\n",
      "149 0.0032620942\n",
      "69 0.0032379199\n",
      "41 0.0031951813\n",
      "237 0.0031764477\n",
      "542 0.0031687487\n",
      "317 0.0031056353\n",
      "642 0.0030981642\n",
      "244 0.0030277558\n",
      "49 0.0030139692\n",
      "331 0.0030126313\n",
      "437 0.0029926454\n",
      "108 0.0029756161\n",
      "840 0.0029584388\n",
      "732 0.0029442534\n",
      "367 0.002914314\n",
      "939 0.0029131917\n",
      "247 0.0029094606\n",
      "945 0.002895289\n",
      "336 0.0028944903\n",
      "45 0.0028874963\n",
      "671 0.0028292544\n",
      "142 0.002817423\n",
      "750 0.002815305\n",
      "162 0.00279694\n",
      "140 0.0027541583\n",
      "356 0.00273746\n",
      "147 0.0027200244\n",
      "150 0.002719326\n",
      "865 0.0027159525\n",
      "982 0.0027085466\n",
      "206 0.002666999\n",
      "658 0.0026323819\n",
      "330 0.0026253955\n",
      "492 0.002606239\n",
      "586 0.0025098068\n",
      "197 0.0025000728\n",
      "374 0.0024794498\n",
      "53 0.002468431\n",
      "426 0.0024666125\n",
      "453 0.0024599172\n",
      "166 0.0024421825\n",
      "468 0.002412156\n",
      "297 0.0024028076\n",
      "70 0.002380227\n",
      "314 0.0023536903\n",
      "791 0.0023331824\n",
      "769 0.0023314985\n",
      "491 0.002329038\n",
      "670 0.0023189043\n",
      "787 0.0023161133\n",
      "445 0.002298372\n",
      "274 0.002286942\n",
      "302 0.0022832486\n",
      "89 0.0022715619\n",
      "8 0.0022705114\n",
      "934 0.00227018\n",
      "211 0.002258475\n",
      "94 0.0022377186\n",
      "800 0.002148398\n",
      "342 0.002078328\n",
      "214 0.0020779371\n",
      "475 0.0020657657\n",
      "537 0.0020656253\n",
      "20 0.0020523707\n",
      "98 0.0020358423\n",
      "452 0.0020283377\n",
      "892 0.0020213171\n",
      "157 0.0020118777\n",
      "967 0.0019782488\n",
      "284 0.0019668352\n",
      "938 0.0019566887\n",
      "921 0.0019344684\n",
      "195 0.0019256156\n",
      "651 0.0019176198\n",
      "490 0.001904412\n",
      "199 0.0018873841\n",
      "828 0.0018482788\n",
      "232 0.0018367867\n",
      "712 0.0018331485\n",
      "749 0.001832106\n",
      "198 0.001830885\n",
      "318 0.0018250365\n",
      "774 0.0018186594\n",
      "110 0.0018008497\n",
      "767 0.0018004263\n",
      "701 0.0017975513\n",
      "868 0.0017962338\n",
      "135 0.0017881914\n",
      "601 0.0017675895\n",
      "941 0.0017608977\n",
      "984 0.001751539\n",
      "466 0.0017481212\n",
      "432 0.001728366\n",
      "324 0.0017255399\n",
      "138 0.0016944709\n",
      "275 0.0016459025\n",
      "424 0.0016357431\n",
      "337 0.0016302641\n",
      "188 0.0016233899\n",
      "979 0.0015982292\n",
      "379 0.0015931623\n",
      "207 0.0015884459\n",
      "14 0.0015814984\n",
      "923 0.0015794885\n",
      "106 0.0015740399\n",
      "745 0.0015427998\n",
      "927 0.0015270334\n",
      "478 0.0015250994\n",
      "405 0.0015108287\n",
      "471 0.0015104233\n",
      "547 0.0014990019\n",
      "74 0.001486562\n",
      "346 0.0014798379\n",
      "482 0.0014744094\n",
      "920 0.0014736357\n",
      "225 0.001471519\n",
      "273 0.001454456\n",
      "59 0.0014517066\n",
      "625 0.0014441538\n",
      "418 0.0014432354\n",
      "527 0.001429357\n",
      "362 0.0014239879\n",
      "309 0.0014029072\n",
      "633 0.0014002643\n",
      "57 0.0013961066\n",
      "178 0.0013792826\n",
      "357 0.0013756022\n",
      "177 0.0013740096\n",
      "718 0.0013551873\n",
      "415 0.0013515367\n",
      "194 0.001350231\n",
      "893 0.0013414477\n",
      "435 0.0013389054\n",
      "493 0.0013373451\n",
      "803 0.0013251279\n",
      "843 0.0013050793\n",
      "303 0.0012884683\n",
      "202 0.0012839837\n",
      "441 0.0012220298\n",
      "973 0.0012197577\n",
      "726 0.0012144434\n",
      "660 0.0011745307\n",
      "392 0.0011643796\n",
      "248 0.0011605185\n",
      "223 0.0011591692\n",
      "279 0.0011503374\n",
      "416 0.0011390452\n",
      "216 0.0010981843\n",
      "871 0.0010650619\n",
      "724 0.0010245664\n",
      "467 0.0010017378\n",
      "182 0.000994692\n",
      "950 0.0009917247\n",
      "646 0.0009742746\n",
      "329 0.00096776086\n",
      "501 0.0009351134\n",
      "307 0.000906498\n",
      "215 0.0009037012\n",
      "234 0.00090357166\n",
      "323 0.0008700766\n",
      "644 0.0008621494\n",
      "811 0.0008592951\n",
      "534 0.00085428223\n",
      "24 0.00083704997\n",
      "180 0.0007815434\n",
      "380 0.0007724102\n",
      "238 0.00076672714\n",
      "508 0.0007572883\n",
      "222 0.0007382118\n",
      "906 0.0007294449\n",
      "562 0.0007189209\n",
      "189 0.0007149594\n",
      "831 0.00071449386\n",
      "494 0.0006999379\n",
      "447 0.0006923318\n",
      "263 0.0006862055\n",
      "578 0.0006847422\n",
      "320 0.00067859393\n",
      "257 0.00067593163\n",
      "829 0.0006481547\n",
      "304 0.0006257933\n",
      "629 0.00062481756\n",
      "737 0.00061397627\n",
      "795 0.0006107188\n",
      "902 0.0006047864\n",
      "591 0.00059278816\n",
      "325 0.0005870134\n",
      "877 0.000580862\n",
      "535 0.0005752346\n",
      "610 0.00056208426\n",
      "382 0.00055876415\n",
      "402 0.00052844535\n",
      "375 0.0005195068\n",
      "539 0.00050893123\n",
      "136 0.00050861406\n",
      "185 0.00050117535\n",
      "85 0.0004966631\n",
      "448 0.00049100374\n",
      "593 0.00048888347\n",
      "619 0.00048595903\n",
      "654 0.00047223162\n",
      "569 0.00046801148\n",
      "359 0.00046439696\n",
      "773 0.00045830297\n",
      "869 0.00045830297\n",
      "381 0.00045821778\n",
      "37 0.00044638012\n",
      "411 0.00043892744\n",
      "179 0.00043581787\n",
      "886 0.00043543766\n",
      "34 0.00041799727\n",
      "86 0.00041534693\n",
      "305 0.00040550923\n",
      "118 0.0004050799\n",
      "723 0.00040244625\n",
      "949 0.00039770408\n",
      "898 0.0003965405\n",
      "790 0.0003944041\n",
      "18 0.00038355426\n",
      "691 0.0003727919\n",
      "637 0.00037263276\n",
      "697 0.00036980928\n",
      "383 0.00036397978\n",
      "667 0.00036371217\n",
      "699 0.0003611552\n",
      "15 0.00036014098\n",
      "50 0.00035691564\n",
      "809 0.00035375968\n",
      "909 0.00035037467\n",
      "458 0.000347436\n",
      "456 0.00034456875\n",
      "117 0.00034066825\n",
      "81 0.00033561862\n",
      "376 0.000333753\n",
      "793 0.00033262017\n",
      "120 0.00032734388\n",
      "444 0.0003096916\n",
      "261 0.00029804817\n",
      "300 0.000297735\n",
      "38 0.00029638375\n",
      "560 0.00028908014\n",
      "351 0.0002851229\n",
      "579 0.0002824821\n",
      "288 0.000272343\n",
      "842 0.00027074537\n",
      "946 0.0002703358\n",
      "13 0.00027024018\n",
      "470 0.00026866028\n",
      "107 0.00025653117\n",
      "394 0.00025595518\n",
      "555 0.0002536813\n",
      "852 0.00025116059\n",
      "17 0.00023730786\n",
      "974 0.00023703865\n",
      "369 0.00023551309\n",
      "170 0.00023349968\n",
      "64 0.00023335085\n",
      "333 0.00023204913\n",
      "25 0.00021913453\n",
      "806 0.0002129376\n",
      "249 0.00020847394\n",
      "837 0.00020271921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291 0.00020134455\n",
      "744 0.00019999804\n",
      "164 0.00019737973\n",
      "308 0.00019177604\n",
      "143 0.0001802579\n",
      "191 0.0001778425\n",
      "123 0.00017116735\n",
      "29 0.00017033303\n",
      "384 0.00016748825\n",
      "239 0.00016429498\n",
      "404 0.00015983131\n",
      "975 0.0001479518\n",
      "474 0.00014546103\n",
      "810 0.0001429547\n",
      "994 0.00014202166\n",
      "826 0.00014125904\n",
      "907 0.00014056358\n",
      "561 0.00013723742\n",
      "134 0.00013451403\n",
      "883 0.0001286793\n",
      "99 0.00012864731\n",
      "28 0.00012388604\n",
      "992 0.00011826202\n",
      "204 0.00011628934\n",
      "708 0.00010818026\n",
      "600 0.00010755598\n",
      "872 9.772619e-05\n",
      "258 9.362336e-05\n",
      "621 9.107958e-05\n",
      "428 8.6798915e-05\n",
      "473 8.4697036e-05\n",
      "316 7.441674e-05\n",
      "665 7.2510506e-05\n",
      "218 7.001735e-05\n",
      "352 6.9621834e-05\n",
      "183 6.9455724e-05\n",
      "72 6.6798064e-05\n",
      "947 6.546286e-05\n",
      "522 6.1778985e-05\n",
      "711 6.0309332e-05\n",
      "988 5.9339913e-05\n",
      "203 5.7587175e-05\n",
      "289 5.6371013e-05\n",
      "295 4.7911613e-05\n",
      "201 4.4506858e-05\n",
      "794 4.402955e-05\n",
      "480 2.8283757e-05\n",
      "937 2.325649e-05\n",
      "87 1.9892126e-05\n",
      "568 1.9154093e-05\n",
      "6 0.0\n",
      "32 0.0\n",
      "40 0.0\n",
      "66 0.0\n",
      "67 0.0\n",
      "68 0.0\n",
      "75 0.0\n",
      "77 0.0\n",
      "78 0.0\n",
      "91 0.0\n",
      "92 0.0\n",
      "96 0.0\n",
      "97 0.0\n",
      "111 0.0\n",
      "112 0.0\n",
      "114 0.0\n",
      "125 0.0\n",
      "159 0.0\n",
      "168 0.0\n",
      "171 0.0\n",
      "175 0.0\n",
      "196 0.0\n",
      "200 0.0\n",
      "212 0.0\n",
      "213 0.0\n",
      "220 0.0\n",
      "226 0.0\n",
      "235 0.0\n",
      "246 0.0\n",
      "276 0.0\n",
      "332 0.0\n",
      "378 0.0\n",
      "395 0.0\n",
      "400 0.0\n",
      "438 0.0\n",
      "451 0.0\n",
      "477 0.0\n",
      "510 0.0\n",
      "571 0.0\n",
      "655 0.0\n",
      "685 0.0\n",
      "698 0.0\n",
      "700 0.0\n",
      "714 0.0\n",
      "716 0.0\n",
      "720 0.0\n",
      "733 0.0\n",
      "734 0.0\n",
      "739 0.0\n",
      "756 0.0\n",
      "760 0.0\n",
      "762 0.0\n",
      "765 0.0\n",
      "772 0.0\n",
      "782 0.0\n",
      "796 0.0\n",
      "802 0.0\n",
      "812 0.0\n",
      "818 0.0\n",
      "845 0.0\n",
      "870 0.0\n",
      "897 0.0\n",
      "901 0.0\n",
      "903 0.0\n",
      "908 0.0\n",
      "930 0.0\n",
      "935 0.0\n",
      "959 0.0\n",
      "977 0.0\n",
      "978 0.0\n",
      "995 0.0\n",
      "1000 0.0\n"
     ]
    }
   ],
   "source": [
    "query_document = \"金融 虎讯 月 日 消息 今日 菏泽市 地方 金融 监督 管理局 发布 该市 失联 小额贷款 公司 公告 显示 菏泽市 牡丹区 恒顺 小额贷款 有限公司 情形 监管 系统 或市 县 两级 地方 金融 监管部门 市场 监管部门 预留 电话 取得联系\".split()\n",
    "query_bow = dictionary.doc2bow(query_document)\n",
    "sims = index[tf_idf[query_bow]]\n",
    "for document_number, score in sorted(enumerate(sims), key=lambda x: x[1], reverse=True):\n",
    "    print(document_number, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "金融 虎讯 月 日 消息 今日 菏泽市 地方 金融 监督 管理局 发布 该市 失联 小额贷款 公司 公告 显示 菏泽市 牡丹区 恒顺 小额贷款 有限公司 情形 监管 系统 或市 县 两级 地方 金融 监管部门 市场 监管部门 预留 电话 取得联系 办公 场所 已转 做 长期 未向 监管 系统 报送 相关 数据 情形 小额贷款 公司 长期 脱离 监管 经营 情况 较大 风险 隐患 现 公告 请 牡丹区 恒顺 小额贷款 有限公司 公告 三十日 主动 该局 提供 相关 资料 情况 逾期 未 主动 山东省 地方 金融 条例 相关 进一步 监管 措施 返回 搜狐 查看 责任编辑\n"
     ]
    }
   ],
   "source": [
    "print(documents[39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-15 09:37:47,189 : INFO : loading projection weights from ../data/sgns.financial.char.bz2\n",
      "2020-06-15 09:37:53,275 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:53,888 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:53,927 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:54,474 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:54,498 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:54,683 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:54,752 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:54,779 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:54,841 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:54,920 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:54,983 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:55,008 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:55,157 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:55,270 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:55,427 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:55,497 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:55,622 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:55,701 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:55,801 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:55,999 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:56,134 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:56,588 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:56,675 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:56,908 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:57,476 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:57,655 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:58,437 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:59,100 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:59,945 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:00,136 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:02,043 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:02,226 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:02,316 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:02,988 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:03,481 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:03,819 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:04,055 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:04,165 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:05,186 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:05,838 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:09,224 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:09,456 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-15 09:38:10,574 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:10,817 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:10,833 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:11,203 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:11,871 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:15,620 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:41:14,951 : INFO : duplicate words detected, shrinking matrix size from 467389 to 467341\n",
      "2020-06-15 09:41:14,951 : INFO : loaded (467341, 300) matrix from ../data/sgns.financial.char.bz2\n"
     ]
    }
   ],
   "source": [
    "#加载预训练金融预料w2v model\n",
    "from gensim.models import KeyedVectors\n",
    "word_vectors_char = KeyedVectors.load_word2vec_format('../data/sgns.financial.char.bz2') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-15 09:41:14,957 : INFO : Removed 12 and 7 OOV words from document 1 and 2 (respectively).\n",
      "2020-06-15 09:41:14,958 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-06-15 09:41:14,960 : INFO : built Dictionary(496 unique tokens: ['CME', 'WTI', '一度', '一段时间', '下跌']...) from 2 documents (total 1150 corpus positions)\n",
      "2020-06-15 09:41:19,222 : INFO : Removed 12 and 24 OOV words from document 1 and 2 (respectively).\n",
      "2020-06-15 09:41:19,222 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-06-15 09:41:19,223 : INFO : built Dictionary(442 unique tokens: ['CME', 'WTI', '一度', '一段时间', '下跌']...) from 2 documents (total 850 corpus positions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance = 3.4920\n",
      "distance = 5.2379\n"
     ]
    }
   ],
   "source": [
    "distance = word_vectors_char.wmdistance(texts[3], texts[44]) #两篇原油宝的文章\n",
    "print('distance = %.4f' % distance)\n",
    "distance = word_vectors_char.wmdistance(texts[3], texts[45]) #一篇原油宝一篇疫情\n",
    "print('distance = %.4f' % distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc2vec example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TaggedDocument(words=['新华社', '哥本哈根', '月', '日电', '记者', '林晶', '世界卫生组织', '欧洲', '区域', '办事处', '主任', '克卢格', '月', '日', '哥本哈根', '视频', '例会', '时', '呼吁', '区域', '各国', '特别', '社区', '传播', '控制', '国家', '应', '确保', '医疗卫生', '系统', '双轨制', '抗击', '新冠', '疫情', '保证', '常规', '医疗卫生', '服务', '运转', '克卢格', '说', '欧洲地区', '新冠', '疫情', '严峻', '一周', '累计', '确诊', '病例', '15%', '累计', '确诊', '病例', '达', '1408266', '例', '同期', '死亡', '病例', '18%', '累计', '死亡', '人数', '达', '129344', '欧洲地区', '累计', '确诊', '死亡', '病例', '占', '世界', '相关', '病例', '数', '46%', '63%', '克卢格', '呼吁', '欧洲各国', '政府', '卫生机构', '寻求', '办法', '控制', '新冠', '病毒', '社区', '传播', '前提', '快速', '恢复', '常规', '医疗卫生', '服务', '特别', '指出', '形势', '保证', '儿童', '接种', '麻疹', '常规', '疫苗', '重要性', '克卢格', '说', '新冠', '疫情', '短时期', '消失', '波', '第三', '波', '疫情', '认知', '动员', '社会', '理解', '协作', '双轨制', '医疗卫生', '系统', '保证', '应对', '新冠', '疫情', '反复', '时', '灵活性', '弹性'], tags=[0]), TaggedDocument(words=['昨晚', '美股', '率先', '突破', '站上', '日', '均线', '创新', '高', '东京', '日经指数', '涨幅', '超', '2%', '创新', '高', 'A股', '大板', '指', '高开高', '走', '上证', '一举', '拿下', '久攻不下', '2850', '点', '成交量', '暴增', '银行', '强', '银行', '板块', '昨天', '起到', '应有', '护盘', '作用', '轮', '证券', '板块', '启动', '大涨', '超', '2%', '上证指数', '支撑', '爆量', '上涨', '资金', '光速', '进场', '资金', '板块', '半导体', '板块', '板块', '指数', '暴涨', '7%', '创', '历史', '单日', '涨幅', '板块', '权重股', '行业龙头', '涨停', '如兆易', '创新', '通富', '微电', '长电', '科技', '沪', '硅', '产业', '板块', '效应', '板块', '效应', '吸引', '资金', '参与', '交易', '好事', '板块', '技术', '面', '短期', '均线', '均线', '粘合', '短期', '平均', '成本', '重叠', '爆量', '暴涨', '站', '上半年', '线', '近半年', '平均', '持仓', '成本', '获利', '人类', '趋利避害', '特性', '越', '赚钱', '越', '持股', '买入', '越', '亏损', '越', '卖出', '恐慌性', '吸引', '资金', '参与', '半导体', '指数', '无线耳机', '板块', '板块', '指数', '涨幅', '超', '5%', '佳禾', '智能', '天', '板', '市场', '龙头股', '华胜天', '成', '突破', '年', '高点', '涨停板', '亿', '资金', '抢筹', '封板', '突破', '趋势', '安洁', '科技', 'PE30', '倍', '估值', '不高', '流通', '市值', '亿', '年线', '启动', '早盘', '开盘', '分钟', '涨停', '速度', '之快', '前所未有', '资金', '心情', '急切', '可见一斑', '华胜天', '成', '科技股', '走势', '板块', '食品饮料', '农林牧渔', '人造肉', '医药', '板块', '究其原因', '逻辑', '是因为', '农林牧渔', '食品饮料', '人造肉', '医药', '消费', '板块', '偏', '防御', '指数', '一跌', '板块', '必涨', '这招', '屡试不爽', 'A股', '市场', '经验', '规律性', '质疑', '当作', '公理', '来记', '当作', '记住', '预计', '指数', '五一', '后先', '延续', '上涨', '态势', '科技股', '领涨', '交易日', '指数', '遇压', '调整', '指数', '调整', '防御性', '板块', '食品饮料', '农林牧渔', '人造肉', '医药', '复制', '前期', '行情', '下图', '农林牧渔', '板块', '指数', '上证指数', '叠加', '图', '上半', '农林牧渔', '板块', '指数', '上证指数', '走势', '农林牧渔', '上证指数', '叠加', '图', '透露', '观察', '市场', '情绪', '指标', '规律', '前天', '早盘', 'A股', '跌停', '数量', '上次', '跌停', '数量', '好巧', '巧合', '市场', '恐慌', '情绪', '聪明', '资金', '一看', '熟悉', '情况', '情绪', '低谷', '来临', '拐点', '到来', '久违', '百股', '涨停', '情绪', '时间', '周期', '情绪', '周期', '高点', '低点', '天', '时间', '低点', '高点', '天', '时间', '时间', '做', '防御性', '板块', '情绪', '低谷', '指标', '市场', '情绪', '退潮', '期时', '市场', '最先', '跌停', '数量', '增多', '连续', '跌停', '股', '数量', '增多', '恐慌性', '顶', '跌停', '数量', '只股', '跌停', '跌停', '数量', '减少', '涨停', '数量', '增多', '高潮', '指标', '充分利用', '市场', '情绪', '拐点', '情绪', '低点', '时', '布局', '情绪', '高潮', '规避', '转向', '防御性', '板块'], tags=[1])]\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "train_corpus = []\n",
    "for i in range(n):\n",
    "    train_corpus.append(gensim.models.doc2vec.TaggedDocument(documents[i].split(), [i]))\n",
    "print(train_corpus[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-15 09:41:21,658 : INFO : collecting all words and their counts\n",
      "2020-06-15 09:41:21,659 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2020-06-15 09:41:21,703 : INFO : collected 35788 word types and 1000 unique tags from a corpus of 1000 examples and 230224 words\n",
      "2020-06-15 09:41:21,704 : INFO : Loading a fresh vocabulary\n",
      "2020-06-15 09:41:21,739 : INFO : effective_min_count=2 retains 16894 unique words (47% of original 35788, drops 18894)\n",
      "2020-06-15 09:41:21,739 : INFO : effective_min_count=2 leaves 211330 word corpus (91% of original 230224, drops 18894)\n",
      "2020-06-15 09:41:21,782 : INFO : deleting the raw counts dictionary of 35788 items\n",
      "2020-06-15 09:41:21,783 : INFO : sample=0.001 downsamples 18 most-common words\n",
      "2020-06-15 09:41:21,784 : INFO : downsampling leaves estimated 203913 word corpus (96.5% of prior 211330)\n",
      "2020-06-15 09:41:21,814 : INFO : estimated required memory for 16894 words and 20 dimensions: 11230040 bytes\n",
      "2020-06-15 09:41:21,815 : INFO : resetting layer weights\n",
      "2020-06-15 09:41:25,040 : INFO : training model with 3 workers on 16894 vocabulary and 20 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-06-15 09:41:25,205 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:25,210 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:25,213 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:25,214 : INFO : EPOCH - 1 : training on 230224 raw words (204913 effective words) took 0.2s, 1230040 effective words/s\n",
      "2020-06-15 09:41:25,364 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:25,366 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:25,371 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:25,372 : INFO : EPOCH - 2 : training on 230224 raw words (204961 effective words) took 0.2s, 1313708 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=20, min_count=2, epochs=40)\n",
    "model.build_vocab(train_corpus)\n",
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = model.infer_vector(['金融','行业','原油宝','期货'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(train_corpus)):\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "\n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "counter = collections.Counter(ranks)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Document ({}): «{}»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('SECOND-MOST', 1), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a random document from the corpus and infer a vector from the model\n",
    "import random\n",
    "doc_id = random.randint(0, len(train_corpus) - 1)\n",
    "\n",
    "# Compare and print the second-most-similar document\n",
    "print('Train Document ({}): «{}»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "sim_id = second_ranks[doc_id]\n",
    "print('Similar Document {}: «{}»\\n'.format(sim_id, ' '.join(train_corpus[sim_id[0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pDL] *",
   "language": "python",
   "name": "conda-env-pDL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
