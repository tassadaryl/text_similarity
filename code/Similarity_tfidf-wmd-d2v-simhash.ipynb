{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stopwords(stopwords_path):\n",
    "    with open(stopwords_path, 'r', encoding='utf-8') as f:\n",
    "        return [line.strip() for line in f]\n",
    "    \n",
    "def preprocess_data(corpus_path, stopwords):\n",
    "    corpus = []\n",
    "    with open(corpus_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            corpus.append(' '.join([word for word in jieba.lcut(line.strip()) if word not in stopwords]))\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "2020-06-15 09:37:30,471 : DEBUG : Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/m3/4yh806w92fdgcn0bk16ql7nw0000gn/T/jieba.cache\n",
      "2020-06-15 09:37:30,474 : DEBUG : Loading model from cache /var/folders/m3/4yh806w92fdgcn0bk16ql7nw0000gn/T/jieba.cache\n",
      "Loading model cost 0.638 seconds.\n",
      "2020-06-15 09:37:31,111 : DEBUG : Loading model cost 0.638 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "2020-06-15 09:37:31,112 : DEBUG : Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "n = 1000\n",
    "stopwords_path = \"../data/stop_words.txt\"\n",
    "documents_path = \"../data/documents_first_\" + str(n) + \".txt\"\n",
    "stopwords = load_stopwords(stopwords_path)\n",
    "documents = preprocess_data(documents_path, stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'董明珠 惊人 之语 炮轰 美的 怒斥 国产车 炮火 引向 大众 这下 本来 习惯于 看热闹 吃 瓜 群众 答应 踩 同行 骂 竞争对手 意见 敢动 老子 一亩 三分 不行 014 月 日 晚间 格力电器 董事长 兼 总裁 董明珠 接受 采访 时 赞同 黄奇帆 取消 住房 公积金 说 格力电器 3700 套 房子 员工 入住 未来 格力 员工 发一 套房 公积金 听听 话 饱汉不知饿汉饥 专程来 炫富 经济 下行 大众 钱包 吃紧 格力 本事 每名 员工 分 房子 本事 格力 分房 取消 全国 公积金 站长 想 问 一句 董 小姐 蠢 坏 确实 格力 优秀 年 营业 收入 1981.53 拥有 万名 员工 格力 万名 员工 发一 套房 站长 说 信 格力 真 员工 分房 中国 企业 众多 能发 房子 企业 凤毛麟角 特别 受 疫情 影响 众多 行业 暴击 企业 濒临 倒闭 活着 不错 每人 发 套房 格力 员工 公积金 取消 公积金 格力 确实 省下 一大笔钱 我国 亿人 贫富差距 取消 公积金 势必会 影响 人群 利益 也许 董明珠 换种 表述 特定 福利 企业 取消 缴纳 公积金 企业 节约 成本 用于 研发 创新 公积金 整体 实施 影响 我国 当初 建立 住房 公积金 制度 新加坡 学习 希望 强制性 缴纳 办法 集合 政府 企业 职工 三方 力量 解决 民众 购房 中国 最先 实行 公积金 政策 上海 全国 房地产 市场 发展 实行 公房 分配制度 家庭 人均 住房面积 七八 平方米 住 拥挤 居住 环境 急需 改善 公积金 强制 缴存 看似 个人收入 减少 长期 并非如此 民企 公积金 缴纳 比例 5% 12% 薪资 基数 缴纳 比例 6% 公司 6% 12% 公积金 存缴 数额 50006% 别看 元不多 长此以往 可不是 小数 缴纳 时间 公积金 买房 提取 大众 福利 特别 事业单位 公务员 群体 公积金 缴纳 金额 高 一般来说 公务员 月 公积金 扣除 比例 工资 12% 公积金 政策 国家 补贴 数额 公务员 一个月 公积金 工资 24% 民企 两倍 账面 工资 特别 高 公务员 群体 公积金 住 建部 人民银行 总行 统计 显示 年 全国 住房 公积金 缴存 总额 14549.46 上年 增长 12.29% 缴存 人数 机关 事业单位 工作人员 国企 职工 缴存 住房 公积金 比例 占 年 缴存 总额 60.16% 占 高 年 城镇 私 民 营 企业 城镇 企业 缴纳 住房 公积金 占 总额 19.5% 公积金 公务员 群体 至关重要 普通人 公积金 房价 高昂 公积金 居民 低息 房贷 唯一 渠道 全国 住房 公积金 年 年度报告 显示 年末 累计 发放 住房贷款 3334.82 万笔 85821.32 人员 置业 首 套房 贷款 年 公积金 利率 3.25% 二套 3.75% 远 商贷 首 套房 贷款 平均 利率 5.5% 假设 贷款 年 期限 公积金 贷款 商业贷款 节省 利息 约 笔 不小 资金 取消 公积金 将会 损害 大部分 利益 举个 例子 刘 缴纳 公积金 比例 12% 月 缴存 652 年 3.25% 利率 贷款 购买 一套 住房 每月 还款 可用 公积金 冲抵 979 每月 还款 多元 公积金 减轻 购房 压力 用处 很大 缴纳 住房 公积金 好处 少 缴纳 个人所得税 计算 个税 减去 住房 公积金 数额 不论是 单位 缴纳 缴纳 实惠 很大 公积金 提取 不断扩大 公积金 效率 提升 买房 装修 可用 租房 大病 提取 当今 疫情 部门 发出通知 新冠 肺炎 患者 提取 住房 公积金 用于 医疗 支出 买房 账户 里 公积金 退休 取出 生活 改善 说 公积金 用处 只能 租房 买房 公积金 表面 事 关乎 国家 大部 利益 开发商 公积金 制度 降低 买房 门槛 买房 人会 有利于 房企 发展 地方 政府 开发商 有钱 买 缴纳 土地 出让金 有利于 地方 财政 说 专家 说 取消 公积金 可取 稍微 动动脑 子 甄别 利弊 类 声音 就行 跑 偏 免责 声明 本文 腾讯 新闻 客户端 媒体 代表 腾讯网 观点 立场'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora\n",
    "from pprint import pprint\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [[word for word in document.split()] for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "frequency = defaultdict(int)\n",
    "for text in texts:\n",
    "    for token in text:\n",
    "        frequency[token] += 1\n",
    "texts = [[token for token in text if frequency[token] > 2] for text in texts]\n",
    "# pprint(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-15 09:37:45,315 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-06-15 09:37:45,481 : INFO : built Dictionary(11105 unique tokens: ['15%', '18%', '46%', '一周', '世界']...) from 1005 documents (total 200743 corpus positions)\n",
      "2020-06-15 09:37:45,483 : INFO : saving Dictionary object under ../data/first_1000_doc.dict, separately None\n",
      "2020-06-15 09:37:45,490 : INFO : saved ../data/first_1000_doc.dict\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(11105 unique tokens: ['15%', '18%', '46%', '一周', '世界']...)\n"
     ]
    }
   ],
   "source": [
    "dictionary = corpora.Dictionary(texts)\n",
    "dictionary.save('../data/first_' + str(n) + '_doc.dict')\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-15 09:37:45,657 : INFO : storing corpus in Matrix Market format to ../data/first_1000_doc.mm\n",
      "2020-06-15 09:37:45,657 : INFO : saving sparse matrix to ../data/first_1000_doc.mm\n",
      "2020-06-15 09:37:45,658 : INFO : PROGRESS: saving document #0\n",
      "2020-06-15 09:37:45,776 : INFO : PROGRESS: saving document #1000\n",
      "2020-06-15 09:37:45,777 : INFO : saved 1005x11105 matrix, density=0.982% (109589/11160525)\n",
      "2020-06-15 09:37:45,778 : INFO : saving MmCorpus index to ../data/first_1000_doc.mm.index\n"
     ]
    }
   ],
   "source": [
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "corpora.MmCorpus.serialize('../data/first_' + str(n) + '_doc.mm', corpus)\n",
    "# pprint(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-15 09:37:45,783 : INFO : collecting document frequencies\n",
      "2020-06-15 09:37:45,784 : INFO : PROGRESS: processing document #0\n",
      "2020-06-15 09:37:45,802 : INFO : calculating IDF weights for 1005 documents and 11105 features (109589 matrix non-zeros)\n"
     ]
    }
   ],
   "source": [
    "from gensim import models, similarities\n",
    "tf_idf = models.TfidfModel(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1),\n",
      "  (1, 1),\n",
      "  (2, 1),\n",
      "  (3, 1),\n",
      "  (4, 1),\n",
      "  (5, 1),\n",
      "  (6, 1),\n",
      "  (7, 1),\n",
      "  (8, 1),\n",
      "  (9, 2),\n",
      "  (10, 1),\n",
      "  (11, 3),\n",
      "  (12, 1),\n",
      "  (13, 4),\n",
      "  (14, 1),\n",
      "  (15, 1),\n",
      "  (16, 1),\n",
      "  (17, 1),\n",
      "  (18, 2),\n",
      "  (19, 4),\n",
      "  (20, 1),\n",
      "  (21, 1),\n",
      "  (22, 2),\n",
      "  (23, 1),\n",
      "  (24, 1),\n",
      "  (25, 1),\n",
      "  (26, 2),\n",
      "  (27, 1),\n",
      "  (28, 1),\n",
      "  (29, 3),\n",
      "  (30, 1),\n",
      "  (31, 1),\n",
      "  (32, 1),\n",
      "  (33, 1),\n",
      "  (34, 1),\n",
      "  (35, 1),\n",
      "  (36, 1),\n",
      "  (37, 1),\n",
      "  (38, 2),\n",
      "  (39, 1),\n",
      "  (40, 1),\n",
      "  (41, 5),\n",
      "  (42, 1),\n",
      "  (43, 1),\n",
      "  (44, 1),\n",
      "  (45, 2),\n",
      "  (46, 2),\n",
      "  (47, 2),\n",
      "  (48, 1),\n",
      "  (49, 1),\n",
      "  (50, 2),\n",
      "  (51, 3),\n",
      "  (52, 2),\n",
      "  (53, 1),\n",
      "  (54, 2),\n",
      "  (55, 1),\n",
      "  (56, 5),\n",
      "  (57, 1),\n",
      "  (58, 5),\n",
      "  (59, 1),\n",
      "  (60, 1),\n",
      "  (61, 1),\n",
      "  (62, 1),\n",
      "  (63, 3),\n",
      "  (64, 1),\n",
      "  (65, 2),\n",
      "  (66, 1),\n",
      "  (67, 2),\n",
      "  (68, 4),\n",
      "  (69, 1),\n",
      "  (70, 1),\n",
      "  (71, 1),\n",
      "  (72, 2),\n",
      "  (73, 2),\n",
      "  (74, 1),\n",
      "  (75, 1)],\n",
      " [(43, 1),\n",
      "  (45, 1),\n",
      "  (76, 2),\n",
      "  (77, 1),\n",
      "  (78, 1),\n",
      "  (79, 3),\n",
      "  (80, 1),\n",
      "  (81, 1),\n",
      "  (82, 1),\n",
      "  (83, 2),\n",
      "  (84, 1),\n",
      "  (85, 4),\n",
      "  (86, 1),\n",
      "  (87, 1),\n",
      "  (88, 1),\n",
      "  (89, 1),\n",
      "  (90, 1),\n",
      "  (91, 1),\n",
      "  (92, 1),\n",
      "  (93, 1),\n",
      "  (94, 1),\n",
      "  (95, 1),\n",
      "  (96, 3),\n",
      "  (97, 2),\n",
      "  (98, 1),\n",
      "  (99, 3),\n",
      "  (100, 2),\n",
      "  (101, 1),\n",
      "  (102, 1),\n",
      "  (103, 1),\n",
      "  (104, 1),\n",
      "  (105, 1),\n",
      "  (106, 1),\n",
      "  (107, 6),\n",
      "  (108, 1),\n",
      "  (109, 1),\n",
      "  (110, 1),\n",
      "  (111, 3),\n",
      "  (112, 1),\n",
      "  (113, 1),\n",
      "  (114, 1),\n",
      "  (115, 1),\n",
      "  (116, 3),\n",
      "  (117, 2),\n",
      "  (118, 2),\n",
      "  (119, 1),\n",
      "  (120, 1),\n",
      "  (121, 1),\n",
      "  (122, 2),\n",
      "  (123, 2),\n",
      "  (124, 2),\n",
      "  (125, 2),\n",
      "  (126, 2),\n",
      "  (127, 2),\n",
      "  (128, 3),\n",
      "  (129, 3),\n",
      "  (130, 1),\n",
      "  (131, 1),\n",
      "  (132, 3),\n",
      "  (133, 1),\n",
      "  (134, 1),\n",
      "  (135, 1),\n",
      "  (136, 7),\n",
      "  (137, 1),\n",
      "  (138, 2),\n",
      "  (139, 1),\n",
      "  (140, 1),\n",
      "  (141, 1),\n",
      "  (142, 1),\n",
      "  (143, 1),\n",
      "  (144, 1),\n",
      "  (145, 1),\n",
      "  (146, 1),\n",
      "  (147, 1),\n",
      "  (148, 10),\n",
      "  (149, 2),\n",
      "  (150, 1),\n",
      "  (151, 2),\n",
      "  (152, 1),\n",
      "  (153, 2),\n",
      "  (154, 1),\n",
      "  (155, 1),\n",
      "  (156, 1),\n",
      "  (157, 1),\n",
      "  (158, 9),\n",
      "  (159, 3),\n",
      "  (160, 1),\n",
      "  (161, 2),\n",
      "  (162, 7),\n",
      "  (163, 2),\n",
      "  (164, 4),\n",
      "  (165, 1),\n",
      "  (166, 1),\n",
      "  (167, 1),\n",
      "  (168, 1),\n",
      "  (169, 2),\n",
      "  (170, 1),\n",
      "  (171, 1),\n",
      "  (172, 1),\n",
      "  (173, 20),\n",
      "  (174, 1),\n",
      "  (175, 1),\n",
      "  (176, 1),\n",
      "  (177, 4),\n",
      "  (178, 1),\n",
      "  (179, 3),\n",
      "  (180, 1),\n",
      "  (181, 1),\n",
      "  (182, 1),\n",
      "  (183, 1),\n",
      "  (184, 2),\n",
      "  (185, 2),\n",
      "  (186, 2),\n",
      "  (187, 1),\n",
      "  (188, 3),\n",
      "  (189, 1),\n",
      "  (190, 1),\n",
      "  (191, 1),\n",
      "  (192, 1),\n",
      "  (193, 1),\n",
      "  (194, 1),\n",
      "  (195, 1),\n",
      "  (196, 1),\n",
      "  (197, 1),\n",
      "  (198, 1),\n",
      "  (199, 1),\n",
      "  (200, 1),\n",
      "  (201, 1),\n",
      "  (202, 1),\n",
      "  (203, 1),\n",
      "  (204, 1),\n",
      "  (205, 2),\n",
      "  (206, 1),\n",
      "  (207, 7),\n",
      "  (208, 1),\n",
      "  (209, 1),\n",
      "  (210, 2),\n",
      "  (211, 1),\n",
      "  (212, 3),\n",
      "  (213, 4),\n",
      "  (214, 1),\n",
      "  (215, 7),\n",
      "  (216, 1),\n",
      "  (217, 1),\n",
      "  (218, 1),\n",
      "  (219, 1),\n",
      "  (220, 1),\n",
      "  (221, 1),\n",
      "  (222, 1),\n",
      "  (223, 1),\n",
      "  (224, 2),\n",
      "  (225, 1),\n",
      "  (226, 3),\n",
      "  (227, 1),\n",
      "  (228, 1),\n",
      "  (229, 1),\n",
      "  (230, 1),\n",
      "  (231, 3),\n",
      "  (232, 2),\n",
      "  (233, 1),\n",
      "  (234, 2),\n",
      "  (235, 3)]]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(corpus[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-15 09:37:45,844 : WARNING : scanning corpus to determine the number of features (consider setting `num_features` explicitly)\n",
      "2020-06-15 09:37:46,342 : INFO : creating matrix with 1005 documents and 11105 features\n"
     ]
    }
   ],
   "source": [
    "index = similarities.MatrixSimilarity(tf_idf[corpus])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 0.8459525\n",
      "483 0.11595668\n",
      "653 0.11566185\n",
      "443 0.08606418\n",
      "622 0.0748373\n",
      "298 0.07418704\n",
      "339 0.071005516\n",
      "327 0.06818734\n",
      "371 0.06796195\n",
      "315 0.06487929\n",
      "348 0.06225711\n",
      "956 0.059957404\n",
      "165 0.05980962\n",
      "996 0.054670077\n",
      "778 0.053686388\n",
      "82 0.052728444\n",
      "597 0.051916204\n",
      "751 0.051364847\n",
      "707 0.043157633\n",
      "846 0.041981574\n",
      "580 0.03954599\n",
      "788 0.038054198\n",
      "296 0.03713871\n",
      "36 0.036963742\n",
      "879 0.0368164\n",
      "21 0.036739632\n",
      "440 0.035467554\n",
      "953 0.033900443\n",
      "35 0.033481337\n",
      "913 0.033455756\n",
      "271 0.03276166\n",
      "221 0.032736387\n",
      "334 0.03246125\n",
      "507 0.03174052\n",
      "499 0.031045455\n",
      "797 0.031032456\n",
      "311 0.030903686\n",
      "312 0.030280098\n",
      "680 0.029878343\n",
      "461 0.029806994\n",
      "116 0.029659348\n",
      "148 0.029653452\n",
      "243 0.029493464\n",
      "113 0.028947107\n",
      "816 0.02846191\n",
      "46 0.028146721\n",
      "669 0.027783422\n",
      "292 0.027584933\n",
      "9 0.027326383\n",
      "520 0.027126888\n",
      "3 0.026542025\n",
      "233 0.02637478\n",
      "65 0.025726298\n",
      "943 0.025676448\n",
      "399 0.025495697\n",
      "807 0.025269594\n",
      "414 0.025067756\n",
      "344 0.024766719\n",
      "532 0.024764955\n",
      "269 0.024758764\n",
      "44 0.02407913\n",
      "88 0.02406754\n",
      "976 0.024049094\n",
      "761 0.023970228\n",
      "505 0.023898652\n",
      "231 0.023809776\n",
      "808 0.023807742\n",
      "931 0.02372852\n",
      "766 0.023541689\n",
      "306 0.02347046\n",
      "682 0.023441236\n",
      "952 0.0231792\n",
      "702 0.023097375\n",
      "955 0.023058642\n",
      "925 0.022994846\n",
      "742 0.022980813\n",
      "932 0.022813337\n",
      "905 0.022527184\n",
      "538 0.021580994\n",
      "1003 0.02149614\n",
      "1004 0.021429028\n",
      "848 0.020818498\n",
      "548 0.020796688\n",
      "450 0.020754026\n",
      "264 0.020428648\n",
      "33 0.020267164\n",
      "713 0.020044\n",
      "540 0.019856654\n",
      "71 0.01980493\n",
      "997 0.019798197\n",
      "710 0.019740097\n",
      "176 0.01957261\n",
      "512 0.019329555\n",
      "442 0.019019343\n",
      "709 0.018791975\n",
      "784 0.018584918\n",
      "777 0.018281804\n",
      "413 0.018274926\n",
      "894 0.018239176\n",
      "740 0.01820739\n",
      "488 0.018160911\n",
      "985 0.018061591\n",
      "914 0.01801332\n",
      "861 0.017973652\n",
      "688 0.017973125\n",
      "390 0.017900769\n",
      "673 0.017754335\n",
      "690 0.017531276\n",
      "83 0.017467303\n",
      "370 0.017463777\n",
      "487 0.017444469\n",
      "368 0.0174179\n",
      "631 0.017387705\n",
      "573 0.017350443\n",
      "741 0.017317902\n",
      "659 0.01728392\n",
      "26 0.017266266\n",
      "434 0.016987707\n",
      "860 0.016949467\n",
      "486 0.01692566\n",
      "358 0.016773654\n",
      "836 0.016687304\n",
      "521 0.016615361\n",
      "747 0.016524037\n",
      "833 0.016478905\n",
      "717 0.016446438\n",
      "526 0.016418846\n",
      "817 0.016364627\n",
      "93 0.016340867\n",
      "880 0.016265165\n",
      "617 0.016165812\n",
      "209 0.01616314\n",
      "338 0.016133413\n",
      "1001 0.016018962\n",
      "511 0.015998857\n",
      "530 0.015861586\n",
      "266 0.015802983\n",
      "780 0.015781725\n",
      "980 0.015748827\n",
      "940 0.015576841\n",
      "867 0.015564129\n",
      "830 0.01554567\n",
      "856 0.015503338\n",
      "366 0.0152174225\n",
      "890 0.015198754\n",
      "661 0.015194453\n",
      "156 0.015182415\n",
      "899 0.015145569\n",
      "372 0.015125547\n",
      "854 0.015098384\n",
      "599 0.015080191\n",
      "48 0.015022256\n",
      "719 0.01497641\n",
      "853 0.014952242\n",
      "589 0.014952017\n",
      "403 0.014813819\n",
      "918 0.014741383\n",
      "942 0.014721248\n",
      "965 0.014647956\n",
      "377 0.014570211\n",
      "972 0.014402019\n",
      "280 0.014375436\n",
      "504 0.014302092\n",
      "609 0.014251909\n",
      "989 0.014119087\n",
      "839 0.01409388\n",
      "95 0.014034981\n",
      "208 0.014016345\n",
      "884 0.013922916\n",
      "799 0.013898806\n",
      "546 0.013889423\n",
      "887 0.013754347\n",
      "145 0.013719084\n",
      "61 0.01371739\n",
      "62 0.01371739\n",
      "970 0.013692651\n",
      "30 0.013662741\n",
      "849 0.01365783\n",
      "397 0.013638547\n",
      "536 0.013493676\n",
      "706 0.01346356\n",
      "764 0.013435889\n",
      "119 0.013419284\n",
      "73 0.01340176\n",
      "1002 0.013380004\n",
      "693 0.013368126\n",
      "102 0.013358718\n",
      "343 0.013357003\n",
      "666 0.013332015\n",
      "757 0.013305471\n",
      "961 0.01329832\n",
      "528 0.013244494\n",
      "550 0.013241175\n",
      "835 0.013202149\n",
      "531 0.013201799\n",
      "259 0.013183735\n",
      "559 0.0131438\n",
      "606 0.01313887\n",
      "172 0.013084939\n",
      "360 0.013080364\n",
      "657 0.013067212\n",
      "864 0.012920048\n",
      "993 0.012799831\n",
      "963 0.012798132\n",
      "821 0.012771011\n",
      "436 0.012744692\n",
      "439 0.01267063\n",
      "692 0.012666022\n",
      "634 0.012665004\n",
      "190 0.012642583\n",
      "529 0.01255367\n",
      "321 0.012551552\n",
      "954 0.012530599\n",
      "863 0.012529839\n",
      "391 0.012492756\n",
      "326 0.012483796\n",
      "916 0.012431432\n",
      "341 0.0123903565\n",
      "838 0.012359274\n",
      "373 0.012334401\n",
      "419 0.012268011\n",
      "227 0.012266483\n",
      "801 0.012261319\n",
      "847 0.012243242\n",
      "746 0.012222341\n",
      "687 0.012194522\n",
      "771 0.012176327\n",
      "900 0.012101294\n",
      "299 0.012027308\n",
      "832 0.011940178\n",
      "293 0.011933926\n",
      "463 0.011859075\n",
      "581 0.011824661\n",
      "969 0.011779866\n",
      "722 0.011768014\n",
      "398 0.011711538\n",
      "345 0.011696376\n",
      "154 0.011679633\n",
      "132 0.01166601\n",
      "361 0.011664896\n",
      "187 0.011576353\n",
      "715 0.011536887\n",
      "217 0.011529416\n",
      "704 0.011498392\n",
      "758 0.0114973225\n",
      "678 0.011470043\n",
      "862 0.011458181\n",
      "350 0.011428165\n",
      "285 0.0114188\n",
      "703 0.01141705\n",
      "910 0.011403209\n",
      "919 0.011394861\n",
      "696 0.011349998\n",
      "705 0.011349713\n",
      "588 0.011301595\n",
      "251 0.011293361\n",
      "549 0.011288628\n",
      "727 0.011280096\n",
      "873 0.011267615\n",
      "254 0.011247331\n",
      "857 0.011226416\n",
      "844 0.0112186745\n",
      "365 0.011187472\n",
      "728 0.011147689\n",
      "768 0.011083928\n",
      "576 0.011077002\n",
      "265 0.010994272\n",
      "643 0.010971654\n",
      "340 0.010946067\n",
      "566 0.010918375\n",
      "614 0.01090236\n",
      "630 0.010871982\n",
      "240 0.010811069\n",
      "554 0.010798652\n",
      "481 0.010751223\n",
      "960 0.010722283\n",
      "689 0.010721899\n",
      "349 0.010721507\n",
      "819 0.010663389\n",
      "514 0.010653119\n",
      "163 0.0106416205\n",
      "754 0.010619136\n",
      "628 0.010610791\n",
      "933 0.010574289\n",
      "396 0.010516328\n",
      "347 0.010514189\n",
      "781 0.010506168\n",
      "668 0.010476142\n",
      "63 0.010470888\n",
      "991 0.010467746\n",
      "823 0.01041852\n",
      "881 0.010409361\n",
      "885 0.010408218\n",
      "11 0.010333599\n",
      "944 0.010308301\n",
      "489 0.010273928\n",
      "855 0.010253893\n",
      "567 0.010196964\n",
      "624 0.010195965\n",
      "500 0.010189418\n",
      "19 0.010169617\n",
      "42 0.010168005\n",
      "524 0.010167408\n",
      "926 0.010139652\n",
      "519 0.0101251025\n",
      "804 0.010078773\n",
      "587 0.010073828\n",
      "577 0.0100366\n",
      "523 0.010021497\n",
      "915 0.009944167\n",
      "462 0.009879185\n",
      "866 0.009859978\n",
      "936 0.009858449\n",
      "552 0.009834217\n",
      "585 0.009831471\n",
      "101 0.009761919\n",
      "412 0.00972664\n",
      "80 0.009726321\n",
      "572 0.009723239\n",
      "181 0.009712976\n",
      "242 0.009706004\n",
      "551 0.009704122\n",
      "229 0.009670564\n",
      "0 0.009649085\n",
      "616 0.009646751\n",
      "603 0.009622529\n",
      "598 0.009585792\n",
      "255 0.009581497\n",
      "409 0.009547256\n",
      "401 0.009539882\n",
      "146 0.009522265\n",
      "60 0.009483869\n",
      "230 0.0094232755\n",
      "684 0.009417028\n",
      "583 0.009413887\n",
      "133 0.009403328\n",
      "582 0.009349246\n",
      "640 0.009343126\n",
      "518 0.009330954\n",
      "968 0.009308417\n",
      "814 0.009303827\n",
      "241 0.009295461\n",
      "449 0.009285266\n",
      "515 0.0092697805\n",
      "889 0.009266546\n",
      "875 0.009245661\n",
      "695 0.009232702\n",
      "615 0.009203902\n",
      "335 0.009158696\n",
      "408 0.009112502\n",
      "605 0.009098757\n",
      "502 0.009093358\n",
      "917 0.009083634\n",
      "638 0.009060083\n",
      "525 0.0090582\n",
      "294 0.008989903\n",
      "595 0.008972568\n",
      "430 0.008971303\n",
      "564 0.008959252\n",
      "144 0.008953859\n",
      "425 0.008952953\n",
      "565 0.008948847\n",
      "731 0.008938251\n",
      "270 0.008902209\n",
      "649 0.0088655185\n",
      "738 0.008848865\n",
      "928 0.008837783\n",
      "825 0.008800756\n",
      "627 0.008714484\n",
      "328 0.008645779\n",
      "422 0.008629123\n",
      "16 0.008619916\n",
      "683 0.008605301\n",
      "783 0.008602429\n",
      "736 0.008547645\n",
      "386 0.008541383\n",
      "981 0.008510889\n",
      "604 0.008508976\n",
      "496 0.008472647\n",
      "173 0.008424825\n",
      "827 0.008412743\n",
      "613 0.008412032\n",
      "962 0.00841076\n",
      "594 0.008402931\n",
      "639 0.008402475\n",
      "951 0.008396983\n",
      "602 0.008371148\n",
      "47 0.008368339\n",
      "647 0.008324591\n",
      "513 0.008282755\n",
      "104 0.008279538\n",
      "301 0.008264467\n",
      "124 0.00825081\n",
      "686 0.008238599\n",
      "575 0.008237029\n",
      "824 0.008202985\n",
      "635 0.0081972685\n",
      "645 0.008157938\n",
      "792 0.0081565585\n",
      "858 0.0081421705\n",
      "636 0.008134548\n",
      "281 0.0080985\n",
      "785 0.008096265\n",
      "681 0.008076099\n",
      "282 0.008052425\n",
      "553 0.008048839\n",
      "498 0.008042469\n",
      "618 0.007994236\n",
      "612 0.007989551\n",
      "533 0.007960616\n",
      "957 0.007956643\n",
      "570 0.007956249\n",
      "129 0.007951501\n",
      "896 0.007927109\n",
      "662 0.0078957705\n",
      "485 0.007863728\n",
      "770 0.007806622\n",
      "4 0.007766793\n",
      "310 0.0077384263\n",
      "986 0.0077301394\n",
      "924 0.007713144\n",
      "322 0.0076818336\n",
      "121 0.007611906\n",
      "205 0.0075717685\n",
      "815 0.0075001246\n",
      "964 0.007449654\n",
      "52 0.0074471817\n",
      "891 0.007422067\n",
      "417 0.007416761\n",
      "623 0.0073561645\n",
      "407 0.0072876518\n",
      "460 0.0072302287\n",
      "469 0.007160329\n",
      "822 0.007137125\n",
      "813 0.0071221227\n",
      "563 0.007116181\n",
      "663 0.0071028583\n",
      "590 0.0070685195\n",
      "626 0.007067938\n",
      "753 0.0070458916\n",
      "592 0.0070158364\n",
      "911 0.0070115356\n",
      "557 0.0070115235\n",
      "922 0.006968905\n",
      "497 0.0069375522\n",
      "759 0.006924753\n",
      "608 0.0068926797\n",
      "958 0.0068485364\n",
      "541 0.006831037\n",
      "574 0.0068216366\n",
      "675 0.0068162433\n",
      "679 0.006792592\n",
      "454 0.006754024\n",
      "904 0.0067271683\n",
      "457 0.00670146\n",
      "677 0.0066794567\n",
      "224 0.006666186\n",
      "509 0.0066404324\n",
      "406 0.0065725734\n",
      "55 0.0065622968\n",
      "122 0.0065607694\n",
      "882 0.0064407927\n",
      "100 0.0064406404\n",
      "128 0.006434063\n",
      "79 0.006420886\n",
      "584 0.0063905986\n",
      "674 0.0063899355\n",
      "2 0.0063714096\n",
      "990 0.0063435156\n",
      "109 0.0063255876\n",
      "152 0.0062954756\n",
      "721 0.0062810844\n",
      "174 0.006269386\n",
      "755 0.00623268\n",
      "611 0.0061950553\n",
      "455 0.0061650397\n",
      "465 0.0061564688\n",
      "672 0.0060952576\n",
      "169 0.0060888515\n",
      "656 0.006014951\n",
      "313 0.0059259157\n",
      "748 0.005884161\n",
      "998 0.005856491\n",
      "596 0.0058496464\n",
      "859 0.0058314074\n",
      "948 0.005821185\n",
      "999 0.0058161486\n",
      "355 0.005814138\n",
      "10 0.0058077034\n",
      "141 0.005778323\n",
      "427 0.005773965\n",
      "58 0.005734167\n",
      "516 0.005719\n",
      "648 0.0056819734\n",
      "971 0.0055952827\n",
      "228 0.005570539\n",
      "161 0.0055598263\n",
      "929 0.0055436697\n",
      "607 0.005531485\n",
      "620 0.005497104\n",
      "236 0.0054686433\n",
      "503 0.0054509356\n",
      "268 0.0054332027\n",
      "12 0.0054197726\n",
      "730 0.005398583\n",
      "158 0.005375438\n",
      "776 0.005339105\n",
      "841 0.005331205\n",
      "851 0.005314352\n",
      "167 0.0053026974\n",
      "641 0.0052983896\n",
      "389 0.0052921833\n",
      "319 0.0052573713\n",
      "153 0.005241195\n",
      "431 0.0052403286\n",
      "130 0.005201329\n",
      "479 0.0051922337\n",
      "410 0.005190413\n",
      "752 0.0051845233\n",
      "76 0.0051617436\n",
      "385 0.005049765\n",
      "545 0.005042947\n",
      "27 0.005038873\n",
      "131 0.0050342297\n",
      "210 0.005006934\n",
      "650 0.0049896333\n",
      "966 0.0049822815\n",
      "506 0.0049413256\n",
      "820 0.0049302294\n",
      "23 0.0049231583\n",
      "459 0.004916173\n",
      "423 0.004910496\n",
      "786 0.004878233\n",
      "664 0.004878193\n",
      "290 0.004845651\n",
      "90 0.0048331213\n",
      "779 0.0048110485\n",
      "250 0.0047674677\n",
      "151 0.0047592074\n",
      "632 0.004734121\n",
      "850 0.004712605\n",
      "421 0.0047042174\n",
      "364 0.0046972474\n",
      "433 0.0046389205\n",
      "139 0.004565962\n",
      "694 0.004561889\n",
      "876 0.0045396937\n",
      "495 0.004523829\n",
      "763 0.004503211\n",
      "874 0.004480455\n",
      "544 0.004459998\n",
      "354 0.0044591273\n",
      "7 0.0044574495\n",
      "186 0.0044574416\n",
      "252 0.004445703\n",
      "245 0.00441138\n",
      "484 0.0044072354\n",
      "105 0.0043817065\n",
      "895 0.0043610577\n",
      "256 0.0043150517\n",
      "262 0.0042880983\n",
      "137 0.0042849323\n",
      "743 0.00428099\n",
      "472 0.004255399\n",
      "429 0.0042394116\n",
      "878 0.0042163352\n",
      "789 0.0042107645\n",
      "54 0.004189565\n",
      "393 0.0041449945\n",
      "272 0.0041309395\n",
      "160 0.0041262144\n",
      "517 0.00411701\n",
      "476 0.004090421\n",
      "283 0.0040825447\n",
      "267 0.004056112\n",
      "278 0.004004473\n",
      "192 0.003984633\n",
      "464 0.003953032\n",
      "446 0.0039327275\n",
      "983 0.0039012926\n",
      "115 0.0038683768\n",
      "725 0.0038666313\n",
      "43 0.003865763\n",
      "556 0.003865382\n",
      "193 0.0038591265\n",
      "676 0.0038124218\n",
      "1 0.0038100707\n",
      "363 0.0038099303\n",
      "277 0.0037851725\n",
      "558 0.0037780907\n",
      "253 0.0037580235\n",
      "652 0.003732406\n",
      "103 0.0037062734\n",
      "126 0.0036957767\n",
      "729 0.0036712836\n",
      "805 0.003669937\n",
      "260 0.0036533587\n",
      "987 0.0036167665\n",
      "775 0.0036118678\n",
      "286 0.0035672493\n",
      "219 0.0035509996\n",
      "798 0.0035448708\n",
      "543 0.0035255312\n",
      "155 0.0035233214\n",
      "353 0.0034820277\n",
      "22 0.0034768975\n",
      "5 0.003472436\n",
      "735 0.0034480053\n",
      "184 0.003444627\n",
      "888 0.0034315214\n",
      "287 0.003430458\n",
      "56 0.0034231408\n",
      "420 0.0033848903\n",
      "127 0.0033750653\n",
      "387 0.0033730832\n",
      "51 0.0033568237\n",
      "84 0.003345826\n",
      "834 0.0033379716\n",
      "912 0.003319397\n",
      "388 0.0033181347\n",
      "31 0.0033096331\n",
      "149 0.0032620942\n",
      "69 0.0032379199\n",
      "41 0.0031951813\n",
      "237 0.0031764477\n",
      "542 0.0031687487\n",
      "317 0.0031056353\n",
      "642 0.0030981642\n",
      "244 0.0030277558\n",
      "49 0.0030139692\n",
      "331 0.0030126313\n",
      "437 0.0029926454\n",
      "108 0.0029756161\n",
      "840 0.0029584388\n",
      "732 0.0029442534\n",
      "367 0.002914314\n",
      "939 0.0029131917\n",
      "247 0.0029094606\n",
      "945 0.002895289\n",
      "336 0.0028944903\n",
      "45 0.0028874963\n",
      "671 0.0028292544\n",
      "142 0.002817423\n",
      "750 0.002815305\n",
      "162 0.00279694\n",
      "140 0.0027541583\n",
      "356 0.00273746\n",
      "147 0.0027200244\n",
      "150 0.002719326\n",
      "865 0.0027159525\n",
      "982 0.0027085466\n",
      "206 0.002666999\n",
      "658 0.0026323819\n",
      "330 0.0026253955\n",
      "492 0.002606239\n",
      "586 0.0025098068\n",
      "197 0.0025000728\n",
      "374 0.0024794498\n",
      "53 0.002468431\n",
      "426 0.0024666125\n",
      "453 0.0024599172\n",
      "166 0.0024421825\n",
      "468 0.002412156\n",
      "297 0.0024028076\n",
      "70 0.002380227\n",
      "314 0.0023536903\n",
      "791 0.0023331824\n",
      "769 0.0023314985\n",
      "491 0.002329038\n",
      "670 0.0023189043\n",
      "787 0.0023161133\n",
      "445 0.002298372\n",
      "274 0.002286942\n",
      "302 0.0022832486\n",
      "89 0.0022715619\n",
      "8 0.0022705114\n",
      "934 0.00227018\n",
      "211 0.002258475\n",
      "94 0.0022377186\n",
      "800 0.002148398\n",
      "342 0.002078328\n",
      "214 0.0020779371\n",
      "475 0.0020657657\n",
      "537 0.0020656253\n",
      "20 0.0020523707\n",
      "98 0.0020358423\n",
      "452 0.0020283377\n",
      "892 0.0020213171\n",
      "157 0.0020118777\n",
      "967 0.0019782488\n",
      "284 0.0019668352\n",
      "938 0.0019566887\n",
      "921 0.0019344684\n",
      "195 0.0019256156\n",
      "651 0.0019176198\n",
      "490 0.001904412\n",
      "199 0.0018873841\n",
      "828 0.0018482788\n",
      "232 0.0018367867\n",
      "712 0.0018331485\n",
      "749 0.001832106\n",
      "198 0.001830885\n",
      "318 0.0018250365\n",
      "774 0.0018186594\n",
      "110 0.0018008497\n",
      "767 0.0018004263\n",
      "701 0.0017975513\n",
      "868 0.0017962338\n",
      "135 0.0017881914\n",
      "601 0.0017675895\n",
      "941 0.0017608977\n",
      "984 0.001751539\n",
      "466 0.0017481212\n",
      "432 0.001728366\n",
      "324 0.0017255399\n",
      "138 0.0016944709\n",
      "275 0.0016459025\n",
      "424 0.0016357431\n",
      "337 0.0016302641\n",
      "188 0.0016233899\n",
      "979 0.0015982292\n",
      "379 0.0015931623\n",
      "207 0.0015884459\n",
      "14 0.0015814984\n",
      "923 0.0015794885\n",
      "106 0.0015740399\n",
      "745 0.0015427998\n",
      "927 0.0015270334\n",
      "478 0.0015250994\n",
      "405 0.0015108287\n",
      "471 0.0015104233\n",
      "547 0.0014990019\n",
      "74 0.001486562\n",
      "346 0.0014798379\n",
      "482 0.0014744094\n",
      "920 0.0014736357\n",
      "225 0.001471519\n",
      "273 0.001454456\n",
      "59 0.0014517066\n",
      "625 0.0014441538\n",
      "418 0.0014432354\n",
      "527 0.001429357\n",
      "362 0.0014239879\n",
      "309 0.0014029072\n",
      "633 0.0014002643\n",
      "57 0.0013961066\n",
      "178 0.0013792826\n",
      "357 0.0013756022\n",
      "177 0.0013740096\n",
      "718 0.0013551873\n",
      "415 0.0013515367\n",
      "194 0.001350231\n",
      "893 0.0013414477\n",
      "435 0.0013389054\n",
      "493 0.0013373451\n",
      "803 0.0013251279\n",
      "843 0.0013050793\n",
      "303 0.0012884683\n",
      "202 0.0012839837\n",
      "441 0.0012220298\n",
      "973 0.0012197577\n",
      "726 0.0012144434\n",
      "660 0.0011745307\n",
      "392 0.0011643796\n",
      "248 0.0011605185\n",
      "223 0.0011591692\n",
      "279 0.0011503374\n",
      "416 0.0011390452\n",
      "216 0.0010981843\n",
      "871 0.0010650619\n",
      "724 0.0010245664\n",
      "467 0.0010017378\n",
      "182 0.000994692\n",
      "950 0.0009917247\n",
      "646 0.0009742746\n",
      "329 0.00096776086\n",
      "501 0.0009351134\n",
      "307 0.000906498\n",
      "215 0.0009037012\n",
      "234 0.00090357166\n",
      "323 0.0008700766\n",
      "644 0.0008621494\n",
      "811 0.0008592951\n",
      "534 0.00085428223\n",
      "24 0.00083704997\n",
      "180 0.0007815434\n",
      "380 0.0007724102\n",
      "238 0.00076672714\n",
      "508 0.0007572883\n",
      "222 0.0007382118\n",
      "906 0.0007294449\n",
      "562 0.0007189209\n",
      "189 0.0007149594\n",
      "831 0.00071449386\n",
      "494 0.0006999379\n",
      "447 0.0006923318\n",
      "263 0.0006862055\n",
      "578 0.0006847422\n",
      "320 0.00067859393\n",
      "257 0.00067593163\n",
      "829 0.0006481547\n",
      "304 0.0006257933\n",
      "629 0.00062481756\n",
      "737 0.00061397627\n",
      "795 0.0006107188\n",
      "902 0.0006047864\n",
      "591 0.00059278816\n",
      "325 0.0005870134\n",
      "877 0.000580862\n",
      "535 0.0005752346\n",
      "610 0.00056208426\n",
      "382 0.00055876415\n",
      "402 0.00052844535\n",
      "375 0.0005195068\n",
      "539 0.00050893123\n",
      "136 0.00050861406\n",
      "185 0.00050117535\n",
      "85 0.0004966631\n",
      "448 0.00049100374\n",
      "593 0.00048888347\n",
      "619 0.00048595903\n",
      "654 0.00047223162\n",
      "569 0.00046801148\n",
      "359 0.00046439696\n",
      "773 0.00045830297\n",
      "869 0.00045830297\n",
      "381 0.00045821778\n",
      "37 0.00044638012\n",
      "411 0.00043892744\n",
      "179 0.00043581787\n",
      "886 0.00043543766\n",
      "34 0.00041799727\n",
      "86 0.00041534693\n",
      "305 0.00040550923\n",
      "118 0.0004050799\n",
      "723 0.00040244625\n",
      "949 0.00039770408\n",
      "898 0.0003965405\n",
      "790 0.0003944041\n",
      "18 0.00038355426\n",
      "691 0.0003727919\n",
      "637 0.00037263276\n",
      "697 0.00036980928\n",
      "383 0.00036397978\n",
      "667 0.00036371217\n",
      "699 0.0003611552\n",
      "15 0.00036014098\n",
      "50 0.00035691564\n",
      "809 0.00035375968\n",
      "909 0.00035037467\n",
      "458 0.000347436\n",
      "456 0.00034456875\n",
      "117 0.00034066825\n",
      "81 0.00033561862\n",
      "376 0.000333753\n",
      "793 0.00033262017\n",
      "120 0.00032734388\n",
      "444 0.0003096916\n",
      "261 0.00029804817\n",
      "300 0.000297735\n",
      "38 0.00029638375\n",
      "560 0.00028908014\n",
      "351 0.0002851229\n",
      "579 0.0002824821\n",
      "288 0.000272343\n",
      "842 0.00027074537\n",
      "946 0.0002703358\n",
      "13 0.00027024018\n",
      "470 0.00026866028\n",
      "107 0.00025653117\n",
      "394 0.00025595518\n",
      "555 0.0002536813\n",
      "852 0.00025116059\n",
      "17 0.00023730786\n",
      "974 0.00023703865\n",
      "369 0.00023551309\n",
      "170 0.00023349968\n",
      "64 0.00023335085\n",
      "333 0.00023204913\n",
      "25 0.00021913453\n",
      "806 0.0002129376\n",
      "249 0.00020847394\n",
      "837 0.00020271921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291 0.00020134455\n",
      "744 0.00019999804\n",
      "164 0.00019737973\n",
      "308 0.00019177604\n",
      "143 0.0001802579\n",
      "191 0.0001778425\n",
      "123 0.00017116735\n",
      "29 0.00017033303\n",
      "384 0.00016748825\n",
      "239 0.00016429498\n",
      "404 0.00015983131\n",
      "975 0.0001479518\n",
      "474 0.00014546103\n",
      "810 0.0001429547\n",
      "994 0.00014202166\n",
      "826 0.00014125904\n",
      "907 0.00014056358\n",
      "561 0.00013723742\n",
      "134 0.00013451403\n",
      "883 0.0001286793\n",
      "99 0.00012864731\n",
      "28 0.00012388604\n",
      "992 0.00011826202\n",
      "204 0.00011628934\n",
      "708 0.00010818026\n",
      "600 0.00010755598\n",
      "872 9.772619e-05\n",
      "258 9.362336e-05\n",
      "621 9.107958e-05\n",
      "428 8.6798915e-05\n",
      "473 8.4697036e-05\n",
      "316 7.441674e-05\n",
      "665 7.2510506e-05\n",
      "218 7.001735e-05\n",
      "352 6.9621834e-05\n",
      "183 6.9455724e-05\n",
      "72 6.6798064e-05\n",
      "947 6.546286e-05\n",
      "522 6.1778985e-05\n",
      "711 6.0309332e-05\n",
      "988 5.9339913e-05\n",
      "203 5.7587175e-05\n",
      "289 5.6371013e-05\n",
      "295 4.7911613e-05\n",
      "201 4.4506858e-05\n",
      "794 4.402955e-05\n",
      "480 2.8283757e-05\n",
      "937 2.325649e-05\n",
      "87 1.9892126e-05\n",
      "568 1.9154093e-05\n",
      "6 0.0\n",
      "32 0.0\n",
      "40 0.0\n",
      "66 0.0\n",
      "67 0.0\n",
      "68 0.0\n",
      "75 0.0\n",
      "77 0.0\n",
      "78 0.0\n",
      "91 0.0\n",
      "92 0.0\n",
      "96 0.0\n",
      "97 0.0\n",
      "111 0.0\n",
      "112 0.0\n",
      "114 0.0\n",
      "125 0.0\n",
      "159 0.0\n",
      "168 0.0\n",
      "171 0.0\n",
      "175 0.0\n",
      "196 0.0\n",
      "200 0.0\n",
      "212 0.0\n",
      "213 0.0\n",
      "220 0.0\n",
      "226 0.0\n",
      "235 0.0\n",
      "246 0.0\n",
      "276 0.0\n",
      "332 0.0\n",
      "378 0.0\n",
      "395 0.0\n",
      "400 0.0\n",
      "438 0.0\n",
      "451 0.0\n",
      "477 0.0\n",
      "510 0.0\n",
      "571 0.0\n",
      "655 0.0\n",
      "685 0.0\n",
      "698 0.0\n",
      "700 0.0\n",
      "714 0.0\n",
      "716 0.0\n",
      "720 0.0\n",
      "733 0.0\n",
      "734 0.0\n",
      "739 0.0\n",
      "756 0.0\n",
      "760 0.0\n",
      "762 0.0\n",
      "765 0.0\n",
      "772 0.0\n",
      "782 0.0\n",
      "796 0.0\n",
      "802 0.0\n",
      "812 0.0\n",
      "818 0.0\n",
      "845 0.0\n",
      "870 0.0\n",
      "897 0.0\n",
      "901 0.0\n",
      "903 0.0\n",
      "908 0.0\n",
      "930 0.0\n",
      "935 0.0\n",
      "959 0.0\n",
      "977 0.0\n",
      "978 0.0\n",
      "995 0.0\n",
      "1000 0.0\n"
     ]
    }
   ],
   "source": [
    "query_document = \"金融 虎讯 月 日 消息 今日 菏泽市 地方 金融 监督 管理局 发布 该市 失联 小额贷款 公司 公告 显示 菏泽市 牡丹区 恒顺 小额贷款 有限公司 情形 监管 系统 或市 县 两级 地方 金融 监管部门 市场 监管部门 预留 电话 取得联系\".split()\n",
    "query_bow = dictionary.doc2bow(query_document)\n",
    "sims = index[tf_idf[query_bow]]\n",
    "for document_number, score in sorted(enumerate(sims), key=lambda x: x[1], reverse=True):\n",
    "    print(document_number, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "金融 虎讯 月 日 消息 今日 菏泽市 地方 金融 监督 管理局 发布 该市 失联 小额贷款 公司 公告 显示 菏泽市 牡丹区 恒顺 小额贷款 有限公司 情形 监管 系统 或市 县 两级 地方 金融 监管部门 市场 监管部门 预留 电话 取得联系 办公 场所 已转 做 长期 未向 监管 系统 报送 相关 数据 情形 小额贷款 公司 长期 脱离 监管 经营 情况 较大 风险 隐患 现 公告 请 牡丹区 恒顺 小额贷款 有限公司 公告 三十日 主动 该局 提供 相关 资料 情况 逾期 未 主动 山东省 地方 金融 条例 相关 进一步 监管 措施 返回 搜狐 查看 责任编辑\n"
     ]
    }
   ],
   "source": [
    "print(documents[39])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-15 09:37:47,189 : INFO : loading projection weights from ../data/sgns.financial.char.bz2\n",
      "2020-06-15 09:37:53,275 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:53,888 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:53,927 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:54,474 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:54,498 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:54,683 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:54,752 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:54,779 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:54,841 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:54,920 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:54,983 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:55,008 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:55,157 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:55,270 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:55,427 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:55,497 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:55,622 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:55,701 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:55,801 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:55,999 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:56,134 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:56,588 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:56,675 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:56,908 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:57,476 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:57,655 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:58,437 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:59,100 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:37:59,945 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:00,136 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:02,043 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:02,226 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:02,316 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:02,988 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:03,481 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:03,819 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:04,055 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:04,165 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:05,186 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:05,838 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:09,224 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:09,456 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-15 09:38:10,574 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:10,817 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:10,833 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:11,203 : WARNING : duplicate word '--------------------------------------------------------------------------------------------------' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:11,871 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:38:15,620 : WARNING : duplicate word '..................................................................................................' in word2vec file, ignoring all but first\n",
      "2020-06-15 09:41:14,951 : INFO : duplicate words detected, shrinking matrix size from 467389 to 467341\n",
      "2020-06-15 09:41:14,951 : INFO : loaded (467341, 300) matrix from ../data/sgns.financial.char.bz2\n"
     ]
    }
   ],
   "source": [
    "#加载预训练金融预料w2v model\n",
    "from gensim.models import KeyedVectors\n",
    "word_vectors_char = KeyedVectors.load_word2vec_format('../data/sgns.financial.char.bz2') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-15 09:41:14,957 : INFO : Removed 12 and 7 OOV words from document 1 and 2 (respectively).\n",
      "2020-06-15 09:41:14,958 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-06-15 09:41:14,960 : INFO : built Dictionary(496 unique tokens: ['CME', 'WTI', '一度', '一段时间', '下跌']...) from 2 documents (total 1150 corpus positions)\n",
      "2020-06-15 09:41:19,222 : INFO : Removed 12 and 24 OOV words from document 1 and 2 (respectively).\n",
      "2020-06-15 09:41:19,222 : INFO : adding document #0 to Dictionary(0 unique tokens: [])\n",
      "2020-06-15 09:41:19,223 : INFO : built Dictionary(442 unique tokens: ['CME', 'WTI', '一度', '一段时间', '下跌']...) from 2 documents (total 850 corpus positions)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance = 3.4920\n",
      "distance = 5.2379\n"
     ]
    }
   ],
   "source": [
    "distance = word_vectors_char.wmdistance(texts[3], texts[44]) #两篇原油宝的文章\n",
    "print('distance = %.4f' % distance)\n",
    "distance = word_vectors_char.wmdistance(texts[3], texts[45]) #一篇原油宝一篇疫情\n",
    "print('distance = %.4f' % distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc2vec example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TaggedDocument(words=['新华社', '哥本哈根', '月', '日电', '记者', '林晶', '世界卫生组织', '欧洲', '区域', '办事处', '主任', '克卢格', '月', '日', '哥本哈根', '视频', '例会', '时', '呼吁', '区域', '各国', '特别', '社区', '传播', '控制', '国家', '应', '确保', '医疗卫生', '系统', '双轨制', '抗击', '新冠', '疫情', '保证', '常规', '医疗卫生', '服务', '运转', '克卢格', '说', '欧洲地区', '新冠', '疫情', '严峻', '一周', '累计', '确诊', '病例', '15%', '累计', '确诊', '病例', '达', '1408266', '例', '同期', '死亡', '病例', '18%', '累计', '死亡', '人数', '达', '129344', '欧洲地区', '累计', '确诊', '死亡', '病例', '占', '世界', '相关', '病例', '数', '46%', '63%', '克卢格', '呼吁', '欧洲各国', '政府', '卫生机构', '寻求', '办法', '控制', '新冠', '病毒', '社区', '传播', '前提', '快速', '恢复', '常规', '医疗卫生', '服务', '特别', '指出', '形势', '保证', '儿童', '接种', '麻疹', '常规', '疫苗', '重要性', '克卢格', '说', '新冠', '疫情', '短时期', '消失', '波', '第三', '波', '疫情', '认知', '动员', '社会', '理解', '协作', '双轨制', '医疗卫生', '系统', '保证', '应对', '新冠', '疫情', '反复', '时', '灵活性', '弹性'], tags=[0]), TaggedDocument(words=['昨晚', '美股', '率先', '突破', '站上', '日', '均线', '创新', '高', '东京', '日经指数', '涨幅', '超', '2%', '创新', '高', 'A股', '大板', '指', '高开高', '走', '上证', '一举', '拿下', '久攻不下', '2850', '点', '成交量', '暴增', '银行', '强', '银行', '板块', '昨天', '起到', '应有', '护盘', '作用', '轮', '证券', '板块', '启动', '大涨', '超', '2%', '上证指数', '支撑', '爆量', '上涨', '资金', '光速', '进场', '资金', '板块', '半导体', '板块', '板块', '指数', '暴涨', '7%', '创', '历史', '单日', '涨幅', '板块', '权重股', '行业龙头', '涨停', '如兆易', '创新', '通富', '微电', '长电', '科技', '沪', '硅', '产业', '板块', '效应', '板块', '效应', '吸引', '资金', '参与', '交易', '好事', '板块', '技术', '面', '短期', '均线', '均线', '粘合', '短期', '平均', '成本', '重叠', '爆量', '暴涨', '站', '上半年', '线', '近半年', '平均', '持仓', '成本', '获利', '人类', '趋利避害', '特性', '越', '赚钱', '越', '持股', '买入', '越', '亏损', '越', '卖出', '恐慌性', '吸引', '资金', '参与', '半导体', '指数', '无线耳机', '板块', '板块', '指数', '涨幅', '超', '5%', '佳禾', '智能', '天', '板', '市场', '龙头股', '华胜天', '成', '突破', '年', '高点', '涨停板', '亿', '资金', '抢筹', '封板', '突破', '趋势', '安洁', '科技', 'PE30', '倍', '估值', '不高', '流通', '市值', '亿', '年线', '启动', '早盘', '开盘', '分钟', '涨停', '速度', '之快', '前所未有', '资金', '心情', '急切', '可见一斑', '华胜天', '成', '科技股', '走势', '板块', '食品饮料', '农林牧渔', '人造肉', '医药', '板块', '究其原因', '逻辑', '是因为', '农林牧渔', '食品饮料', '人造肉', '医药', '消费', '板块', '偏', '防御', '指数', '一跌', '板块', '必涨', '这招', '屡试不爽', 'A股', '市场', '经验', '规律性', '质疑', '当作', '公理', '来记', '当作', '记住', '预计', '指数', '五一', '后先', '延续', '上涨', '态势', '科技股', '领涨', '交易日', '指数', '遇压', '调整', '指数', '调整', '防御性', '板块', '食品饮料', '农林牧渔', '人造肉', '医药', '复制', '前期', '行情', '下图', '农林牧渔', '板块', '指数', '上证指数', '叠加', '图', '上半', '农林牧渔', '板块', '指数', '上证指数', '走势', '农林牧渔', '上证指数', '叠加', '图', '透露', '观察', '市场', '情绪', '指标', '规律', '前天', '早盘', 'A股', '跌停', '数量', '上次', '跌停', '数量', '好巧', '巧合', '市场', '恐慌', '情绪', '聪明', '资金', '一看', '熟悉', '情况', '情绪', '低谷', '来临', '拐点', '到来', '久违', '百股', '涨停', '情绪', '时间', '周期', '情绪', '周期', '高点', '低点', '天', '时间', '低点', '高点', '天', '时间', '时间', '做', '防御性', '板块', '情绪', '低谷', '指标', '市场', '情绪', '退潮', '期时', '市场', '最先', '跌停', '数量', '增多', '连续', '跌停', '股', '数量', '增多', '恐慌性', '顶', '跌停', '数量', '只股', '跌停', '跌停', '数量', '减少', '涨停', '数量', '增多', '高潮', '指标', '充分利用', '市场', '情绪', '拐点', '情绪', '低点', '时', '布局', '情绪', '高潮', '规避', '转向', '防御性', '板块'], tags=[1])]\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "train_corpus = []\n",
    "for i in range(n):\n",
    "    train_corpus.append(gensim.models.doc2vec.TaggedDocument(documents[i].split(), [i]))\n",
    "print(train_corpus[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-15 09:41:21,658 : INFO : collecting all words and their counts\n",
      "2020-06-15 09:41:21,659 : INFO : PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "2020-06-15 09:41:21,703 : INFO : collected 35788 word types and 1000 unique tags from a corpus of 1000 examples and 230224 words\n",
      "2020-06-15 09:41:21,704 : INFO : Loading a fresh vocabulary\n",
      "2020-06-15 09:41:21,739 : INFO : effective_min_count=2 retains 16894 unique words (47% of original 35788, drops 18894)\n",
      "2020-06-15 09:41:21,739 : INFO : effective_min_count=2 leaves 211330 word corpus (91% of original 230224, drops 18894)\n",
      "2020-06-15 09:41:21,782 : INFO : deleting the raw counts dictionary of 35788 items\n",
      "2020-06-15 09:41:21,783 : INFO : sample=0.001 downsamples 18 most-common words\n",
      "2020-06-15 09:41:21,784 : INFO : downsampling leaves estimated 203913 word corpus (96.5% of prior 211330)\n",
      "2020-06-15 09:41:21,814 : INFO : estimated required memory for 16894 words and 20 dimensions: 11230040 bytes\n",
      "2020-06-15 09:41:21,815 : INFO : resetting layer weights\n",
      "2020-06-15 09:41:25,040 : INFO : training model with 3 workers on 16894 vocabulary and 20 features, using sg=0 hs=0 sample=0.001 negative=5 window=5\n",
      "2020-06-15 09:41:25,205 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:25,210 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:25,213 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:25,214 : INFO : EPOCH - 1 : training on 230224 raw words (204913 effective words) took 0.2s, 1230040 effective words/s\n",
      "2020-06-15 09:41:25,364 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:25,366 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:25,371 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:25,372 : INFO : EPOCH - 2 : training on 230224 raw words (204961 effective words) took 0.2s, 1313708 effective words/s\n",
      "2020-06-15 09:41:25,523 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:25,525 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:25,529 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:25,529 : INFO : EPOCH - 3 : training on 230224 raw words (204903 effective words) took 0.2s, 1316834 effective words/s\n",
      "2020-06-15 09:41:25,676 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:25,680 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:25,681 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:25,682 : INFO : EPOCH - 4 : training on 230224 raw words (204903 effective words) took 0.2s, 1361155 effective words/s\n",
      "2020-06-15 09:41:25,834 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:25,836 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:25,840 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:25,840 : INFO : EPOCH - 5 : training on 230224 raw words (204907 effective words) took 0.2s, 1306653 effective words/s\n",
      "2020-06-15 09:41:25,988 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:25,989 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:25,993 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:25,993 : INFO : EPOCH - 6 : training on 230224 raw words (204971 effective words) took 0.2s, 1356074 effective words/s\n",
      "2020-06-15 09:41:26,142 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:26,144 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:26,149 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:26,150 : INFO : EPOCH - 7 : training on 230224 raw words (204930 effective words) took 0.2s, 1325492 effective words/s\n",
      "2020-06-15 09:41:26,321 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:26,325 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:26,327 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:26,327 : INFO : EPOCH - 8 : training on 230224 raw words (205035 effective words) took 0.2s, 1166100 effective words/s\n",
      "2020-06-15 09:41:26,481 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:26,484 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:26,487 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:26,488 : INFO : EPOCH - 9 : training on 230224 raw words (204913 effective words) took 0.2s, 1293827 effective words/s\n",
      "2020-06-15 09:41:26,634 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:26,635 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:26,638 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:26,639 : INFO : EPOCH - 10 : training on 230224 raw words (204890 effective words) took 0.1s, 1369866 effective words/s\n",
      "2020-06-15 09:41:26,794 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:26,795 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:26,800 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:26,801 : INFO : EPOCH - 11 : training on 230224 raw words (204842 effective words) took 0.2s, 1279725 effective words/s\n",
      "2020-06-15 09:41:26,973 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:26,979 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:26,980 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:26,980 : INFO : EPOCH - 12 : training on 230224 raw words (205047 effective words) took 0.2s, 1153645 effective words/s\n",
      "2020-06-15 09:41:27,138 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:27,142 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:27,144 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:27,145 : INFO : EPOCH - 13 : training on 230224 raw words (204898 effective words) took 0.2s, 1256756 effective words/s\n",
      "2020-06-15 09:41:27,308 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:27,314 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:27,321 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:27,322 : INFO : EPOCH - 14 : training on 230224 raw words (204887 effective words) took 0.2s, 1165995 effective words/s\n",
      "2020-06-15 09:41:27,498 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:27,505 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:27,509 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:27,510 : INFO : EPOCH - 15 : training on 230224 raw words (204901 effective words) took 0.2s, 1107972 effective words/s\n",
      "2020-06-15 09:41:27,660 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:27,663 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:27,668 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:27,668 : INFO : EPOCH - 16 : training on 230224 raw words (204914 effective words) took 0.2s, 1308824 effective words/s\n",
      "2020-06-15 09:41:27,822 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:27,824 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:27,829 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:27,829 : INFO : EPOCH - 17 : training on 230224 raw words (204945 effective words) took 0.2s, 1289594 effective words/s\n",
      "2020-06-15 09:41:27,973 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-15 09:41:27,974 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:27,978 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:27,978 : INFO : EPOCH - 18 : training on 230224 raw words (204927 effective words) took 0.1s, 1397517 effective words/s\n",
      "2020-06-15 09:41:28,126 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:28,130 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:28,133 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:28,134 : INFO : EPOCH - 19 : training on 230224 raw words (204811 effective words) took 0.2s, 1332538 effective words/s\n",
      "2020-06-15 09:41:28,306 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:28,308 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:28,312 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:28,312 : INFO : EPOCH - 20 : training on 230224 raw words (204967 effective words) took 0.2s, 1165646 effective words/s\n",
      "2020-06-15 09:41:28,484 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:28,489 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:28,495 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:28,496 : INFO : EPOCH - 21 : training on 230224 raw words (204842 effective words) took 0.2s, 1133268 effective words/s\n",
      "2020-06-15 09:41:28,655 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:28,655 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:28,657 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:28,658 : INFO : EPOCH - 22 : training on 230224 raw words (204942 effective words) took 0.2s, 1285148 effective words/s\n",
      "2020-06-15 09:41:28,802 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:28,805 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:28,810 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:28,810 : INFO : EPOCH - 23 : training on 230224 raw words (204958 effective words) took 0.2s, 1357867 effective words/s\n",
      "2020-06-15 09:41:28,953 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:28,958 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:28,962 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:28,963 : INFO : EPOCH - 24 : training on 230224 raw words (204883 effective words) took 0.2s, 1358325 effective words/s\n",
      "2020-06-15 09:41:29,117 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:29,120 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:29,123 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:29,123 : INFO : EPOCH - 25 : training on 230224 raw words (204807 effective words) took 0.2s, 1293659 effective words/s\n",
      "2020-06-15 09:41:29,265 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:29,267 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:29,272 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:29,273 : INFO : EPOCH - 26 : training on 230224 raw words (204940 effective words) took 0.1s, 1390348 effective words/s\n",
      "2020-06-15 09:41:29,416 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:29,416 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:29,420 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:29,421 : INFO : EPOCH - 27 : training on 230224 raw words (204968 effective words) took 0.1s, 1406609 effective words/s\n",
      "2020-06-15 09:41:29,560 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:29,562 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:29,567 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:29,567 : INFO : EPOCH - 28 : training on 230224 raw words (204944 effective words) took 0.1s, 1414281 effective words/s\n",
      "2020-06-15 09:41:29,708 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:29,709 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:29,715 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:29,715 : INFO : EPOCH - 29 : training on 230224 raw words (204909 effective words) took 0.1s, 1401785 effective words/s\n",
      "2020-06-15 09:41:29,854 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:29,857 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:29,862 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:29,863 : INFO : EPOCH - 30 : training on 230224 raw words (204918 effective words) took 0.1s, 1412268 effective words/s\n",
      "2020-06-15 09:41:30,003 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:30,004 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:30,009 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:30,009 : INFO : EPOCH - 31 : training on 230224 raw words (204815 effective words) took 0.1s, 1415794 effective words/s\n",
      "2020-06-15 09:41:30,145 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:30,147 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:30,154 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:30,154 : INFO : EPOCH - 32 : training on 230224 raw words (204932 effective words) took 0.1s, 1428445 effective words/s\n",
      "2020-06-15 09:41:30,303 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:30,304 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:30,309 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:30,310 : INFO : EPOCH - 33 : training on 230224 raw words (204927 effective words) took 0.2s, 1346458 effective words/s\n",
      "2020-06-15 09:41:30,458 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:30,459 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:30,465 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:30,466 : INFO : EPOCH - 34 : training on 230224 raw words (204883 effective words) took 0.2s, 1330684 effective words/s\n",
      "2020-06-15 09:41:30,617 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:30,619 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:30,623 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:30,623 : INFO : EPOCH - 35 : training on 230224 raw words (204830 effective words) took 0.2s, 1322694 effective words/s\n",
      "2020-06-15 09:41:30,767 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:30,769 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:30,774 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:30,774 : INFO : EPOCH - 36 : training on 230224 raw words (204924 effective words) took 0.1s, 1372095 effective words/s\n",
      "2020-06-15 09:41:30,914 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:30,916 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:30,920 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:30,920 : INFO : EPOCH - 37 : training on 230224 raw words (204922 effective words) took 0.1s, 1421387 effective words/s\n",
      "2020-06-15 09:41:31,059 : INFO : worker thread finished; awaiting finish of 2 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-15 09:41:31,062 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:31,066 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:31,066 : INFO : EPOCH - 38 : training on 230224 raw words (204877 effective words) took 0.1s, 1415895 effective words/s\n",
      "2020-06-15 09:41:31,205 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:31,206 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:31,211 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:31,212 : INFO : EPOCH - 39 : training on 230224 raw words (205017 effective words) took 0.1s, 1423861 effective words/s\n",
      "2020-06-15 09:41:31,348 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2020-06-15 09:41:31,351 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2020-06-15 09:41:31,356 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2020-06-15 09:41:31,357 : INFO : EPOCH - 40 : training on 230224 raw words (204924 effective words) took 0.1s, 1428884 effective words/s\n",
      "2020-06-15 09:41:31,357 : INFO : training on a 9208960 raw words (8196627 effective words) took 6.3s, 1297617 effective words/s\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.doc2vec.Doc2Vec(vector_size=20, min_count=2, epochs=40)\n",
    "model.build_vocab(train_corpus)\n",
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03995954 -0.1329282  -0.04240548 -0.248606   -0.11900987  0.06127899\n",
      "  0.27710456 -0.3751939   0.23243082  0.09699579  0.0797852   0.26121157\n",
      " -0.04011713  0.15084654 -0.1159015  -0.01896799 -0.20620263 -0.7013185\n",
      " -0.14376396 -0.23553611]\n"
     ]
    }
   ],
   "source": [
    "vector = model.infer_vector(['金融','行业','原油宝','期货'])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-06-15 09:41:31,379 : INFO : precomputing L2-norms of doc weight vectors\n"
     ]
    }
   ],
   "source": [
    "ranks = []\n",
    "second_ranks = []\n",
    "for doc_id in range(len(train_corpus)):\n",
    "    inferred_vector = model.infer_vector(train_corpus[doc_id].words)\n",
    "    sims = model.docvecs.most_similar([inferred_vector], topn=len(model.docvecs))\n",
    "    rank = [docid for docid, sim in sims].index(doc_id)\n",
    "    ranks.append(rank)\n",
    "\n",
    "    second_ranks.append(sims[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 979, 1: 7, 6: 3, 2: 3, 5: 3, 3: 2, 43: 1, 30: 1, 12: 1})\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "counter = collections.Counter(ranks)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document (999): «新华社 耶路撒冷 月 日电 记者 尚昊 陈文仙 以色列 财政部 日 以色列 当天 亚洲 市场 首次 发行 债券 发行 总额 达 亿美元 财政部 本轮 债券 年期 利率 3.8% 旨在 以色列政府 减少 因新冠 疫情 财政赤字 疫情 发生 以色列 陆续 推出 多项 措施 应对 疫情 经济 冲击 月 日 以色列 推出 亿新 谢克尔 约合 228 亿美元 财政 救助 计划 规模 相当于 国内 生产总值 6% 月 日 以色列 面向 欧美 市场 发行 总额 达 亿美元 债券 月 日 以色列 中央银行 基准利率 0.25% 降至 0.1% 以色列 央行 本月 发布 数据 显示 受 疫情 影响 第一季度 以色列 经济 下滑 约 5% 预计 年 经济 萎缩 5.3% 以色列 卫生部 日晚 发布 新冠 疫情 数据 显示 疫情 发生 该国 累计 确诊 15834 例 累计 死亡 215 例 累计 治愈 8233 例»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/m,d20,n5,w5,mc2,s0.001,t3):\n",
      "\n",
      "MOST (999, 0.9756925106048584): «新华社 耶路撒冷 月 日电 记者 尚昊 陈文仙 以色列 财政部 日 以色列 当天 亚洲 市场 首次 发行 债券 发行 总额 达 亿美元 财政部 本轮 债券 年期 利率 3.8% 旨在 以色列政府 减少 因新冠 疫情 财政赤字 疫情 发生 以色列 陆续 推出 多项 措施 应对 疫情 经济 冲击 月 日 以色列 推出 亿新 谢克尔 约合 228 亿美元 财政 救助 计划 规模 相当于 国内 生产总值 6% 月 日 以色列 面向 欧美 市场 发行 总额 达 亿美元 债券 月 日 以色列 中央银行 基准利率 0.25% 降至 0.1% 以色列 央行 本月 发布 数据 显示 受 疫情 影响 第一季度 以色列 经济 下滑 约 5% 预计 年 经济 萎缩 5.3% 以色列 卫生部 日晚 发布 新冠 疫情 数据 显示 疫情 发生 该国 累计 确诊 15834 例 累计 死亡 215 例 累计 治愈 8233 例»\n",
      "\n",
      "SECOND-MOST (238, 0.8729859590530396): «新华社 东京 月 日电 记者 刘春燕 日本参议院 月 日 批准 总额 达 25.69 万亿日元 美元 约合 107 日元 史 大规模 补充 预算案 补充 预算 用于 应对 新冠 疫情 众议院 已于 日 这一 补充 预算案 参议院 批准 意味着 财年 补充 预算案 国会 得以 财务 省 补充 预算 资金 发行 国债 筹措 日本国会 月 日 批准 总额 102.7 万亿日元 财年 年 月 财政 预算案 制定 预算案 时 日本政府 预测 财年 日本 经济 增长率 1.4% 专家 媒体 普遍认为 这一 预测 乐观 应对 新冠 疫情 经济 冲击 日本首相 安倍晋三 指示 内阁 成员 着手 编制 财年 补充 预算案 日本政府 月 日 总额 108 万亿日元 史 大规模 经济 刺激 计划 月 日 117 万亿日元 补充 预算案 随之 修改»\n",
      "\n",
      "MEDIAN (895, 0.39511638879776): «小七 参考 仓位 五六成 仓 市场 大大的 惊喜 苦熬 一周 终于 迎来 爆发 提前 昨天 年 月底 几天 苦闷 去年 月 一周 沪 指 横盘 跌 涨 个股 跌停板 数量 几十个 百个 月 日 利空 出尽 效果 市场 开启 一波 印象 深刻 反攻 七祖 回顾 希望 市场 月初 迎来 苦尽甘来 昨天 提前 总体 符合 预期 看多 月 憋 这么久 希望 收获 中午 七祖 说 市场 走出 好于 预期 态势 北上 资金 介入 情况 量 放大 两市 昨天上午 亿 全天 亿 因素 年报 季报 业绩 利空 出尽 市场 轻装上阵 一点 去年 月底 惯例 疫情 影响 七成 股票 季报 业绩 预减 预亏 预期 业绩 大幅 下滑 投资者 信心 一种 打压 昨天晚上 业绩 报告 完 延迟 昨夜 美股 财报 经济 数据 好于 预期 外盘 大涨 3% 超 预期 美国 一季度 GDP 初值 萎缩 4.8% 创 年 四季度 降幅 美股 龙头企业 科技股 疫情 影响 受益 于次 疫情 推动 云 业务 增长 微软 最新 财季 利润 收入 双双 超 预期 Facebook 一季度 收入 高于 预期 近期 奈飞 亚马逊 股价 创 历史 新高 疫情 刺激 销售 特斯拉 一个多月 股价 翻倍 利好 科技股 走强 刺激 中国 科技股 爆发 美股 昨夜 大涨 美股 股指 期货 表现 不错 持续 翻红 小涨 A股 反弹 提供 助力 双会 时间 昨天 敲定 市场 政策 预期 疫情 判断 趋稳 风险 偏好 提升 七祖 节点 开会 做 窗口期 五一 放假 五天 因素 影响 加仓 外盘 不确定性 三天 脱节 以往 利空 事件 有人 焦头烂额 疫情 中国 发展 更好 他腾 出手 肯定 捣乱 两天 集成电路 出口 中国 家 电信 运营商 审查 逻辑 破事 五月 做 顺理成章 事情 疫情 好转 经济 恢复 点 挺进 沪 指 楔形 结构 向下 跌破 完毕 小五浪 三浪 调整 创新 高 技术 上行 macd 成功 死叉 切换 零轴 倒 接受 沪 指日线 级别 里 看清楚 分钟 里 路线 清晰 浪形 日 敲定 路线 操作 完全正确 后续 走出 新 浪 形来 四大 指数 类似 结构 楔形 向下 跌破 诱空 转身 向上 谋求 突破 领涨 特斯拉 锂电池 板块 七祖 昨天晚上 按语 重点 分析 特斯拉 创始人 马斯克 上海 领导 视频会议 车型 降价 有利于 补贴 销量 产业链 利好 一个多月 特斯拉 股价 美元 涨到 美元 翻 一倍 特斯拉 概念股 低位 月份 新能源 车 销量 恢复 产业链 补涨 前景 看好 汽车行业 刺激 政策 高看 一线 特斯拉 整体 表现 不错 贡献 涨停板 经济社会 恢复正常 风向标 两点 芯片 板块 领涨 七祖 看好 板块 板块 ETF 推 芯片 ETF 新能源 车 ETF 芯片 ETF 三次 筑底 说 0.9 买 卖 节奏 板块 K 线 走势图 七祖 日 做出 精准 预判 跌到 低 买点 前天 破前 低 底 背离 绝佳 买点 三次 纪律 操作 芯片 板块 筑底 过程 收益率 芯片 板块 突破 迹象 贡献 涨停 消息面 昨天 说 几个 国外 中国 进口 集成电路 增加 无非 刺激 国产 实质性 作用 华为 意法 半导体 合作 名字 意大利 法国 芯片 企业 麻烦 一季度 华为 手机 唯一 销量 增长 品牌 手机芯片 超过 高通 位居 第一 国产 芯片 想象 空间 手机 高端 未来 PC 端 服务器 芯片 各类 物 联网 芯片 未来 十年 看好 行业 买 芯片 ETF 放心 买 后续 资金 持续 力 一次性 看高 前高 1.4 难度 条件 做点 波段 选股 选择 芯片 ETF 新能源 车 ETF 新能车 ETF 大方向 错 个股 踩 雷 选错 板块 行业 不会错 科技股 领涨 全场 开心 想象 空间 昨天 双会 时间 敲定 后续 新 基建 基建 反复 活跃 5G 6G 活跃 民航 旅游 五一 复苏 板块 稍 总体 疫情 主导 行情 逻辑 淡化 瑞德 西韦 几个 供应商 概念 稍 强 一点 领跌 包括 疫苗 新冠 检测 领跌 品种 前期 抗跌 视频 饮料 板块 北上 资金 流入 情况 弱 一点 疫苗 板块 领跌 未 名医药 短线 涨 一倍 肯定 修复 疫苗 肯定 年底 板块 反复 活跃 反复 做 短期 陈薇 院士 疫苗 项目 月 揭盲 希望 好消息 消息 说 中国 第四个 新冠 疫苗 获 临床 批件 刚刚 启动 临床试验 多条 路线 攻关 总该有 成功 盘后 消息 文旅部 介绍 全国 旅游 景区 开放 故宫 国家博物馆 月 日起 恢复 开放 五一 长假 出游 热情 高 旅游 景区 做好 疫情 防控 错峰 开放 限量 开放 预约 开放 上期 通知 期货 燃料油 仓储 费由原 1.4 吨 • 天 提高 吨 • 天 早 日 上海 原油期货 仓储 费 标准 约 桶 月 调高到 约 桶 月 几天 美国 原油 负 油价 原因 仓储 库容 紧张 节后 看好 原油 运输 仓储 板块 业绩 估计 不错 下周 中午 稍微 担心 午后 有没有 跳水 节前 谨慎 因素 三天 里外 盘 震荡 向上 走势 节后 第一天 延续 升势 重仓 持股 过节 三天 里 回撤 节后 第一天 补跌 仓位 高 担心 尾盘 回落 原因 一般来说 抛 压要 小于 倒数 第二天 盘面 午后 有过 两小波 跳水 支撑 走势 健康 月份 奠定 基调 沪 深 四大 指数 刷 反弹 新高 长假 期间 外盘 幺 蛾子 至少 五月 开门红 可能性 机构 仓位 略有 增加 幅度 节点 稍微 尴尬 周三 程度 上涨 七祖会 毫不犹豫 向上 加仓到 晚上 八点 欧股 高开低走 下挫 1% 美股 股指 期货 微跌 0.5% 影响 周二 见分晓 说 打破 僵局 改变 仓位 策略 急 跌 下探 跌到 加仓 位置 几天 跌到 2750 加到 六成 不跌 要涨 带量 突破 加仓 这时候 带量 突破 冲着 点去 这时候 加仓 好多 板块 股票 低位 说 特斯拉 芯片 分化 季报 业绩 下降 幅度 资金 喜欢 大盘 小盘 科创板 里 好票 走势 确实 稍微 意外 开盘 翻红 指数 涨 0.5% 挺 走得 盯 十几个 晒 仓位 咖 仓位 增加 很快 徐小明 四成 仓位 狂龙 空仓 踏空 越甲 说 甩 下车 昨天 芯片 撤 补 一点 特斯拉 好运 哥 轻仓 水平 wu2198 前天 从空 仓加 20% 加 20% 四成 仓位 老范 林奇 股 社区 八九成 仓位 短线 参考 意义 七祖 选择 五六成 仓位 过节 昨天 五成 高 一点 六成 不算 重仓 昨天 钱 眼海哥 说 重仓 持股 过节 变数 确实 办法 赌 一把 长假 里 坑 认输 感觉 市场 惊喜 爽爽快快 冲高 点 一周 持续 跌停板 大于 涨停板 指数 涨出 亏 钱 效应 巴掌 一颗 糖 牛皮 哄哄 A股 幸运 事情 月 看多 一蹴而就 周二 按语 时 外盘 走势 假期 数据 政策 做 预判 暂且 放宽心 欢度 五一劳动节 市场 活跃 操作 频繁 七祖 提醒 关注 券商 佣金 收费 情况 七祖 下方 长期 推荐 海通 证券 开户 万分之 1.5 佣金 率 主 账户 放到 海通 佣金 确实 便宜 佣金 率 高于 万分之 1.5 建议 券商 砍 砍价 不行 换 海通 点击 阅读 原文 链接 介绍 扫描 上方 二维码 近期 好礼 相送 A股 天花板 返回 搜狐 查看 责任编辑»\n",
      "\n",
      "LEAST (625, -0.19111168384552002): «回家 列车 期待 理想 生活 优质 居所 一纸 蓝图 恢弘 实景 家 眼见为实 月 日 民生 绿城 百合 新城 楼盘 详情 户型图 相册 地图 0635 8800777 二期 盛大 交付 爱 百合 幸福 归家 归家 有期 所见 美好 一把 钥匙 承载 崭新 美好 家 更是 点滴 匠心 汇聚 承诺 民生 绿城 百合 新城 倾付 匠心 交付 时 完美 绽放 早早 百合 新城 工作人员 严阵以待 业主 归家 感受 交付 现场 精心 布置 鲜花 地毯 专人 陪同 层层 精心 装扮 回家 路 充满 仪式 感 入户 大堂 新房 府邸 透漏 业主 尊贵 悉心 服务 美好 相伴 交付 活动 百合 新城 业主 交心 之约 更是 服务 品质 提升 之旅 资料 审核 交房 手续 实地 验房 百合 新城 工作人员 解析 交付 流程 细节 力求 尽善尽美 细节 之处 用心 交房 过程 工作人员 专职 陪同 现场 解说 手续 办理 领取 钥匙 环节 谨慎 细致 用心 服务 业主 带来 温暖 美好生活 精雕细琢 匠心 锤炼 穿过 绿树 掩映 法式 庭院 迈入 恢弘 大气 品质 居所 一草一木 一梯 一门 透漏 优雅 细节 推 门 迈入 美好 家 映入眼帘 宽境 空间 家 美好 充满 无限 验房 过程 专业 工程 人员 置业 顾问 工作人员 陪同 家 交付 园区 景观 实景 呈现 更是 建筑 品质 实力 兑现 整体 构造 房屋 细节 工程 人员 解答 详细 解读 力求 每位 业主 放心 满意 爱 百合 幸福 归家 爱 百合 幸福 家 从今天起 家 梦想 生活 日常 从今天起 美好生活 如约 今日 交付给 业主 不单单是 一串 钥匙 一套 房子 更是 百合 新城 匠心 祝福 完美 新房 交付 业主 百合 新城 保证 质量 前提 确保 节点 工期 充分调动 合理配置 资源 提高 施工 效率 协调 工作 交付 提供 保障 每位 业主 准时 入住 美好 家 民生 绿城 百合 新城 美好生活 如约 相关 房产信息 请 点击 聊城 房产 楼盘 大全 聊城 房产资讯 聊城 房价 聊城 二手房 聊城 楼盘 工程进度 播报»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Document ({}): «{}»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('SECOND-MOST', 1), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(train_corpus[sims[index][0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Document (885): «挖贝网 月 日 华海 药业 600521 今日 发布 年 第一季度 报告 公告 显示 报告 期内 营收 570 555 260.04 同比 增长 30.98% 归属于 上市公司 股东 净利润 220 665 904.93 同比 增长 62.74% 挖贝网 报告 期内 营收 570 555 260.04 同比 增长 30.98% 系 国内 制剂 原料药 销售 大幅 增加 影响 报告 期内 销售费用 同比 增长 66% 系 国内 制剂 销售 力度 加大 国内 制剂 销售 大幅 增加 保证 新 产品 上市 销售 市场调研 前期 费用 大幅 投入 加大 线上 专家 学术 大讲堂 强化 互联网 学术 教育 平台 建设 相关 费用 增加 资料 显示 华海 药业 剂型 仿制 药 生物 药 创新 药及 特色 原料药 研发 生产 销售 集研 产 销为 一体 大型 高新技术 医药企业 来源 链接 sse disclosure listedinfo announcement 600521 20200430 pdf»\n",
      "\n",
      "Similar Document (684, 0.8764888644218445): «挖贝网 月 日 消息 新 药业 600329 发布 年 第一季度 报告 报告期 营业 收入 655 960 806.79 同比 减少 5.56% 归属于 上市公司 股东 净利润 169 889 787.25 同比 减少 10.59% 第一季度 经营 活动 现金流量 净额 138 077 046.98 上年 同期 增长 20.07% 每股 收益 0.221 股 报告 期内 财务费用 882 603.42 上年 同期 693 024.71 利息费用 同比 减少 挖贝网 资料 显示 新 药业 业务 中药材 中成药 中药饮片 西药 制剂 医药 保健品 加工 批 兼 制造 来源 链接 static cninfo finalpage 1207689816 PDF»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pick a random document from the corpus and infer a vector from the model\n",
    "import random\n",
    "doc_id = random.randint(0, len(train_corpus) - 1)\n",
    "\n",
    "# Compare and print the second-most-similar document\n",
    "print('Train Document ({}): «{}»\\n'.format(doc_id, ' '.join(train_corpus[doc_id].words)))\n",
    "sim_id = second_ranks[doc_id]\n",
    "print('Similar Document {}: «{}»\\n'.format(sim_id, ' '.join(train_corpus[sim_id[0]].words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import codecs\n",
    "import math\n",
    "BITS = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class simHash(object):\n",
    "# 初始化，遍历文档（已分词），得到词汇表，并进行32位(能表示2^32种情况，完全足够)\\\n",
    "#hash编码和对应的idf值，将idf值作为其权重进行运算，分别存入两个字典(dict)\n",
    "    def __init__(self, documents):\n",
    "        f = documents\n",
    "        dictHash = dict()\n",
    "        dictWeight = dict()\n",
    "        i = 0#hash编码\n",
    "        lines = 0#记录文本数量,以计算idf值\n",
    "        #遍历文本，进行hash编码和统计df词频(在多少篇文章出现过，而不是总词频，\\\n",
    "        #比如某个词在一个文本中出现三次也只算一次)\n",
    "        for line in f:\n",
    "            lines += 1\n",
    "            temp = set(str(line).strip().split())#避免重复统计词频\n",
    "            for item in temp:\n",
    "                if item not in stopwords:\n",
    "                    if item not in dictWeight:\n",
    "                        dictWeight[item] = 1\n",
    "                        dictHash[item] = i\n",
    "                        i += 1\n",
    "                    else:\n",
    "                        dictWeight[item] += 1\n",
    "        del i\n",
    "        #hash编码转为array形式的二进制，方便计算\n",
    "        for item in dictHash:\n",
    "            L = list(bin(dictHash[item]))[2:]\n",
    "            intL = [int(x) for x in L]\n",
    "            for i in range(len(intL)):\n",
    "                if intL[i] == 0:\n",
    "                    intL[i] = -1\n",
    "            intL = (BITS - len(intL))*[-1]+intL\n",
    "            dictHash[item] = np.array(intL)\n",
    "        #根据词频计算idf值\n",
    "        for item in dictWeight:\n",
    "            dictWeight[item] = math.log(lines/dictWeight[item])\n",
    "\n",
    "        self.dictHash = dictHash\n",
    "        self.dictWeight = dictWeight\n",
    "        \n",
    "    #根据词的hash对句子进行hash编码\n",
    "    def senHash(self, sen):\n",
    "        senHashCode = np.zeros(BITS)\n",
    "        temp = sen.strip().split()\n",
    "        for item in temp:\n",
    "            senHashCode += self.dictHash[item]*self.dictWeight[item]\n",
    "        for i in range(BITS):\n",
    "            if senHashCode[i] > 0:\n",
    "                senHashCode[i] = 1\n",
    "            else:\n",
    "                senHashCode[i] = 0\n",
    "        return senHashCode\n",
    "\n",
    "    #获取两个句子的Hamming distance，dis越小说明相似度越高\n",
    "    def sen2senDis(self, sen1, sen2):\n",
    "        temp1 = self.senHash(sen1)\n",
    "        temp2 = self.senHash(sen2)\n",
    "        Hamming = 0\n",
    "        for i in range(BITS):\n",
    "            if temp1[i] != temp2[i]:\n",
    "                Hamming += 1\n",
    "        return Hamming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "simhash = simHash(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1  1\n",
      "  1  1 -1  1 -1  1  1]\n",
      "2.7230880784667506\n"
     ]
    }
   ],
   "source": [
    "print(simhash.dictHash['金融'])\n",
    "print(simhash.dictWeight['金融'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simhash.sen2senDis(documents[885], documents[684])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 304\n"
     ]
    }
   ],
   "source": [
    "minSimHash = 10000\n",
    "minSimHashIndex = -1\n",
    "for i in range(1, n):\n",
    "    temp = simhash.sen2senDis(documents[0], documents[i])\n",
    "    if temp < minSimHash:\n",
    "        minSimHash = temp\n",
    "        minSimHashIndex = i\n",
    "        \n",
    "print(minSimHash, minSimHashIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "新华社 哥本哈根 月 日电 记者 林晶 世界卫生组织 欧洲 区域 办事处 主任 克卢格 月 日 哥本哈根 视频 例会 时 呼吁 区域 各国 特别 社区 传播 控制 国家 应 确保 医疗卫生 系统 双轨制 抗击 新冠 疫情 保证 常规 医疗卫生 服务 运转 克卢格 说 欧洲地区 新冠 疫情 严峻 一周 累计 确诊 病例 15% 累计 确诊 病例 达 1408266 例 同期 死亡 病例 18% 累计 死亡 人数 达 129344 欧洲地区 累计 确诊 死亡 病例 占 世界 相关 病例 数 46% 63% 克卢格 呼吁 欧洲各国 政府 卫生机构 寻求 办法 控制 新冠 病毒 社区 传播 前提 快速 恢复 常规 医疗卫生 服务 特别 指出 形势 保证 儿童 接种 麻疹 常规 疫苗 重要性 克卢格 说 新冠 疫情 短时期 消失 波 第三 波 疫情 认知 动员 社会 理解 协作 双轨制 医疗卫生 系统 保证 应对 新冠 疫情 反复 时 灵活性 弹性\n",
      "月 日 统计数据 荷兰 累计 感染 病例 38802 例 4711 死亡 医务人员 补充 道 新冠 病毒感染 死亡 病例 新增 例 升至 4795 例 超过 1.07 医院 接受 治疗 世卫 组织 月 日 COVID 疫情 定性 流行 世卫 组织 最新 数据 全球 累计 确诊 万多例 新冠 病毒感染 病例 累计 死亡 20.8 万多例\n"
     ]
    }
   ],
   "source": [
    "print(documents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "月 日 统计数据 荷兰 累计 感染 病例 38802 例 4711 死亡 医务人员 补充 道 新冠 病毒感染 死亡 病例 新增 例 升至 4795 例 超过 1.07 医院 接受 治疗 世卫 组织 月 日 COVID 疫情 定性 流行 世卫 组织 最新 数据 全球 累计 确诊 万多例 新冠 病毒感染 病例 累计 死亡 20.8 万多例\n"
     ]
    }
   ],
   "source": [
    "print(documents[304])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pDL] *",
   "language": "python",
   "name": "conda-env-pDL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
